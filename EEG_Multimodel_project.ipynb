{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9111d97",
   "metadata": {
    "_sphinx_cell_id": "0f98f313-c450-494f-9cbb-093c3eb59f83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --- 1. Define Your Paths ---\n",
    "# (Update these paths to match your system)\n",
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "\n",
    "# --- 2. Define Your Subject List ---\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "\n",
    "# --- 3. Define Image Transforms (e.g., for CLIP) ---\n",
    "# (You would get the specific transforms from your model)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 4. Create the 3 Datasets (Train/Val/Test) ---\n",
    "# This perfectly follows the paper's \"split by session\" rule.\n",
    "\n",
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], # 3 sessions for training\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Validation Dataset...\")\n",
    "val_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-04'], # 1 session for validation\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Test Dataset...\")\n",
    "test_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-05'], # 1 session for testing\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "# --- 5. Create PyTorch DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- 6. Test the loader ---\n",
    "print(\"\\nTesting the training loader...\")\n",
    "eeg_batch, image_batch, caption_batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"EEG batch shape:   {eeg_batch.shape}\")\n",
    "print(f\"Image batch shape: {image_batch.shape}\")\n",
    "print(f\"Caption batch (first item): '{caption_batch[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd3f27",
   "metadata": {
    "_sphinx_cell_id": "4ae854a8-d47e-460f-b06c-8bec4ab7c424"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --- 1. Define Your Paths ---\n",
    "# (Update these paths to match your system)\n",
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "\n",
    "# --- 2. Define Your Subject List ---\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "\n",
    "# --- 3. Define Image Transforms (e.g., for CLIP) ---\n",
    "# (You would get the specific transforms from your model)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 4. Create the 3 Datasets (Train/Val/Test) ---\n",
    "# This perfectly follows the paper's \"split by session\" rule.\n",
    "\n",
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], # 3 sessions for training\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Validation Dataset...\")\n",
    "val_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-04'], # 1 session for validation\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Test Dataset...\")\n",
    "test_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-05'], # 1 session for testing\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "# --- 5. Create PyTorch DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- 6. Test the loader ---\n",
    "print(\"\\nTesting the training loader...\")\n",
    "eeg_batch, image_batch, caption_batch = next(iter(train_loader))\n",
    "\n",
    "print(f\"EEG batch shape:   {eeg_batch.shape}\")\n",
    "print(f\"Image batch shape: {image_batch.shape}\")\n",
    "print(f\"Caption batch (first item): '{caption_batch[0]}'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
