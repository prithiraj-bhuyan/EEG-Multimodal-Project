{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "# Set Seed\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"âœ… Using device: {DEVICE}\")\n",
    "\n",
    "# Login to WandB\n",
    "# wandb.login(key=\"YOUR_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0200246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EEG_Paper_Replication_Dataset(Dataset):\n",
    "    def __init__(self, bids_root, images_dir, captions_path, \n",
    "                 subject_list, session_list, \n",
    "                 clamp_thres=500, stats=None):\n",
    "        \n",
    "        self.bids_root = bids_root\n",
    "        self.images_dir = images_dir\n",
    "        self.clamp_thres = clamp_thres\n",
    "        self.trial_metadata = []\n",
    "        \n",
    "        # --- Create Subject Mapping ---\n",
    "        # Map 'sub-02' -> 0, 'sub-03' -> 1, etc.\n",
    "        # We sort to ensure consistency across Train/Val/Test sets\n",
    "        self.subject_to_idx = {sub: i for i, sub in enumerate(sorted(list(set(subject_list))))}\n",
    "        \n",
    "        # 1. Load Captions Helper\n",
    "        self.captions_dict = self._load_captions(captions_path)\n",
    "        self.category_to_idx = {cat: i for i, cat in enumerate(sorted(set(c for c, _ in self.captions_dict.values())))}\n",
    "        \n",
    "        # 2. Scan Metadata\n",
    "        print(f\"Scanning metadata for {session_list}...\")\n",
    "        for sub in subject_list:\n",
    "            for ses in session_list:\n",
    "                for run in ['01', '02', '03', '04']:\n",
    "                    session_path = os.path.join(self.bids_root, sub, ses)\n",
    "                    csv_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_image.csv\")\n",
    "                    npy_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_1000Hz.npy\")\n",
    "                    \n",
    "                    if not (os.path.exists(csv_path) and os.path.exists(npy_path)):\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        csv_data = pd.read_csv(csv_path)\n",
    "                        for i, row in csv_data.iterrows():\n",
    "                            img_base_name = self._get_base_name(row['FilePath'])\n",
    "                            if not img_base_name: continue\n",
    "                            \n",
    "                            category, caption = self.captions_dict.get(img_base_name, (None, None))\n",
    "                            if not category: continue\n",
    "                            \n",
    "                            self.trial_metadata.append({\n",
    "                                'npy_path': npy_path,\n",
    "                                'trial_index': i,\n",
    "                                'label': self.category_to_idx[category],\n",
    "                                'subject_id': self.subject_to_idx[sub] \n",
    "                            })\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Found {len(self.trial_metadata)} trials.\")\n",
    "\n",
    "        # 3. Compute Global Statistics (GFS)\n",
    "        if stats is None:\n",
    "            print(\"Computing Global Statistics (this takes ~1 min)...\")\n",
    "            self.mean, self.std = self._compute_global_stats()\n",
    "        else:\n",
    "            self.mean, self.std = stats\n",
    "\n",
    "    def _compute_global_stats(self):\n",
    "        subset_indices = range(0, len(self.trial_metadata), 10)\n",
    "        sum_x = 0\n",
    "        sum_sq_x = 0\n",
    "        count = 0\n",
    "        \n",
    "        for i in tqdm(subset_indices, desc=\"Calculating Stats\"):\n",
    "            meta = self.trial_metadata[i]\n",
    "            d = np.load(meta['npy_path'])[meta['trial_index']]\n",
    "            d = np.clip(d, -self.clamp_thres, self.clamp_thres)\n",
    "            \n",
    "            sum_x += np.mean(d)\n",
    "            sum_sq_x += np.mean(d**2)\n",
    "            count += 1\n",
    "            \n",
    "        global_mean = sum_x / count\n",
    "        global_std = np.sqrt((sum_sq_x / count) - (global_mean**2))\n",
    "        return float(global_mean), float(global_std)\n",
    "\n",
    "    def get_stats(self): return self.mean, self.std\n",
    "\n",
    "    def _load_captions(self, path):\n",
    "        d = {}\n",
    "        with open(path, 'r') as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 4: d[parts[2]] = (parts[1], parts[3])\n",
    "        return d\n",
    "\n",
    "    def _get_base_name(self, p):\n",
    "        try:\n",
    "            bn = os.path.splitext(os.path.basename(str(p).replace('\\\\', '/')))[0]\n",
    "            if bn.endswith('_resized'): return bn[:-8]\n",
    "            return bn\n",
    "        except: return None\n",
    "\n",
    "    def __len__(self): return len(self.trial_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.trial_metadata[idx]\n",
    "        eeg_data = np.load(meta['npy_path'])[meta['trial_index']]\n",
    "        eeg_data = np.clip(eeg_data, -self.clamp_thres, self.clamp_thres)\n",
    "        \n",
    "        # Global Feature Standardization\n",
    "        eeg_data = (eeg_data - self.mean) / (self.std + 1e-6)\n",
    "        \n",
    "        return (torch.tensor(eeg_data, dtype=torch.float32), \n",
    "                torch.tensor(meta['label'], dtype=torch.long),\n",
    "                torch.tensor(meta['subject_id'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create Transforms (Standard ImageNet stats)\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Instantiate Training Dataset\n",
    "print(\"--- Init Train ---\")\n",
    "train_ds = EEG_Paper_Replication_Dataset(\n",
    "    bids_root=BIDS_ROOT, \n",
    "    images_dir=IMAGE_DIR, \n",
    "    captions_path=CAPTIONS_FILE, \n",
    "    subject_list=ALL_SUBJECTS, \n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], \n",
    "    clamp_thres=500\n",
    ")\n",
    "# Save stats to use for validation (Prevent data leakage)\n",
    "stats = train_ds.get_stats()\n",
    "\n",
    "# 3. Instantiate Validation Dataset\n",
    "print(\"\\n--- Init Validation ---\")\n",
    "val_ds = EEG_Paper_Replication_Dataset(\n",
    "    bids_root=BIDS_ROOT, \n",
    "    images_dir=IMAGE_DIR, \n",
    "    captions_path=CAPTIONS_FILE, \n",
    "    subject_list=ALL_SUBJECTS, \n",
    "    session_list=['ses-04'], \n",
    "    clamp_thres=500,\n",
    "    stats=stats # <--- IMPORTANT: Use training stats\n",
    ")\n",
    "\n",
    "# 4. Define The Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"\\nâœ… Loaders Ready: {len(train_loader)} training batches, {len(val_loader)} validation batches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ViT_1D(nn.Module):\n",
    "    def __init__(self, num_subjects=13, num_classes=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Hyperparameters ---\n",
    "        self.patch_size = 50      # 50ms window \n",
    "        self.stride = 25          # 50% overlap\n",
    "        self.embed_dim = 128      # Feature size\n",
    "        self.num_heads = 4\n",
    "        self.depth = 2\n",
    "        \n",
    "        # --- 1. Tokenizer (The \"Patchify\" Step) ---\n",
    "        # Input: (Batch, 122, 500) -> Output: (Batch, 128, ~19)\n",
    "        self.tokenizer = nn.Sequential(\n",
    "            nn.Conv1d(122, self.embed_dim, kernel_size=self.patch_size, stride=self.stride, padding=0),\n",
    "            nn.BatchNorm1d(self.embed_dim),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        # --- 2. Learnable \"Class Token\" ---\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embed_dim))\n",
    "        \n",
    "        # --- 3. Positional Embedding ---\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 32, self.embed_dim) * 0.01)\n",
    "        \n",
    "        # --- 4. Transformer Encoder ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dim, \n",
    "            nhead=self.num_heads, \n",
    "            dim_feedforward=512, \n",
    "            dropout=0.5, \n",
    "            batch_first=True,\n",
    "            norm_first=True \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=self.depth)\n",
    "        \n",
    "        # --- 5. Subject-Specific Heads ---\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(self.embed_dim, num_classes) for _ in range(num_subjects)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, subject_ids):\n",
    "        # Input comes in as (Batch, 500, 122) -> We need (Batch, 122, 500)\n",
    "        if x.shape[1] == 500 and x.shape[2] == 122:\n",
    "            x = x.permute(0, 2, 1)\n",
    "            \n",
    "        # Safety Crop (in case data is >500)\n",
    "        if x.shape[2] > 500:\n",
    "            x = x[:, :, :500]\n",
    "            \n",
    "        # ----------------------------------------\n",
    "        \n",
    "        # 1. Tokenize\n",
    "        x = self.tokenizer(x)     # Output: (Batch, 128, 19)\n",
    "        x = x.permute(0, 2, 1)    # Output: (Batch, 19, 128) -> (Batch, Seq, Dim)\n",
    "        \n",
    "        b, seq_len, _ = x.shape\n",
    "        \n",
    "        # 2. Append CLS Token\n",
    "        cls_tokens = self.cls_token.expand(b, -1, -1) \n",
    "        x = torch.cat((cls_tokens, x), dim=1) # (Batch, 20, 128)\n",
    "        \n",
    "        # 3. Add Positional Embedding\n",
    "        x = x + self.pos_embedding[:, :seq_len + 1, :]\n",
    "        \n",
    "        # 4. Transformer Attention\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 5. Extract ONLY the CLS token output\n",
    "        cls_output = x[:, 0, :]   # (Batch, 128)\n",
    "        \n",
    "        # 6. Subject Routing\n",
    "        logits = torch.zeros(x.shape[0], 20).to(x.device)\n",
    "        unique_subs = torch.unique(subject_ids)\n",
    "        \n",
    "        for sub in unique_subs:\n",
    "            mask = (subject_ids == sub)\n",
    "            logits[mask] = self.heads[sub.long()](cls_output[mask])\n",
    "            \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e815fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_TRAINING = False\n",
    "CHECKPOINT_PATH = \"best_model_vit_1d.pth\"\n",
    "TOTAL_EPOCHS = 100\n",
    "\n",
    "wandb.init(\n",
    "    project=\"eeg-classification\",\n",
    "    name=\"vit-1d-run\",\n",
    "    config={\n",
    "        \"architecture\": \"ViT-1D\",\n",
    "        \"dataset\": \"GFS\",\n",
    "        \"epochs\": TOTAL_EPOCHS,\n",
    "        \"lr\": 1e-3\n",
    "    }\n",
    ")\n",
    "\n",
    "model = EEG_ViT_1D(num_subjects=13, num_classes=20).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_acc = 0.0\n",
    "\n",
    "if RESUME_TRAINING and os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"ðŸ”„ Attempting to resume from {CHECKPOINT_PATH}...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "        \n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "            best_val_acc = checkpoint.get('val_acc', 0.0)\n",
    "            print(f\"âœ… Resuming from Epoch {start_epoch} with Best Acc {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"âš ï¸ Only weights found. Resuming from Epoch 1.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading checkpoint: {e}. Starting fresh.\")\n",
    "else:\n",
    "    print(\"ðŸ†• Starting a fresh training run.\")\n",
    "\n",
    "print(f\"\\nðŸš€ Training from Epoch {start_epoch} to {TOTAL_EPOCHS}...\")\n",
    "\n",
    "for epoch in range(start_epoch, TOTAL_EPOCHS + 1):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for eeg, label, sub_id in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        eeg, label, sub_id = eeg.to(DEVICE), label.to(DEVICE), sub_id.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(eeg, sub_id)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred = outputs.max(1)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        total += label.size(0)\n",
    "        \n",
    "    train_acc = 100. * correct / total\n",
    "    \n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg, label, sub_id in val_loader:\n",
    "            eeg, label, sub_id = eeg.to(DEVICE), label.to(DEVICE), sub_id.to(DEVICE)\n",
    "            outputs = model(eeg, sub_id)\n",
    "            _, pred = outputs.max(1)\n",
    "            val_correct += pred.eq(label).sum().item()\n",
    "            val_total += label.size(0)\n",
    "            \n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch:02d}: Train Acc {train_acc:.2f}% | Val Acc {val_acc:.2f}%\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"train_loss\": loss.item()\n",
    "    })\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'train_acc': train_acc\n",
    "        }, CHECKPOINT_PATH)\n",
    "        \n",
    "        wandb.save(CHECKPOINT_PATH) \n",
    "        \n",
    "        print(f\"  âœ… Best Model Saved & Uploaded! ({val_acc:.2f}%)\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Loading Test Set (Session 5)...\")\n",
    "test_ds = EEG_Paper_Replication_Dataset(\n",
    "    BIDS_ROOT, IMAGE_DIR, CAPTIONS_FILE, ALL_SUBJECTS, \n",
    "    ['ses-05'], # FINAL TEST SET\n",
    "    stats=stats,\n",
    "    clamp_thres=500\n",
    ")\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "def evaluate_detailed(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    subject_results = {i: {'correct': 0, 'total': 0} for i in range(len(ALL_SUBJECTS))}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg, label, sub_id in tqdm(loader, desc=\"Testing\"):\n",
    "            eeg, label, sub_id = eeg.to(device), label.to(device), sub_id.to(device)\n",
    "            \n",
    "            outputs = model(eeg, sub_id)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "            for i in range(len(label)):\n",
    "                sid = sub_id[i].item()\n",
    "                is_correct = (preds[i] == label[i]).item()\n",
    "                subject_results[sid]['total'] += 1\n",
    "                subject_results[sid]['correct'] += is_correct\n",
    "                \n",
    "    return all_labels, all_preds, subject_results\n",
    "\n",
    "print(\"Running Final Evaluation...\")\n",
    "y_true, y_pred, sub_metrics = evaluate_detailed(model, test_loader, DEVICE)\n",
    "\n",
    "overall_acc = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"\\nðŸ† Final Test Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "sub_accs = []\n",
    "sub_names = []\n",
    "for sid, metrics in sub_metrics.items():\n",
    "    if metrics['total'] > 0:\n",
    "        acc = (metrics['correct'] / metrics['total']) * 100\n",
    "        sub_accs.append(acc)\n",
    "        sub_names.append(ALL_SUBJECTS[sid])\n",
    "        \n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=sub_names, y=sub_accs, palette=\"viridis\")\n",
    "plt.axhline(y=overall_acc, color='r', linestyle='--', label=f'Avg: {overall_acc:.1f}%')\n",
    "plt.axhline(y=5.0, color='gray', linestyle='--', label='Random Chance (5%)')\n",
    "plt.title(\"Per-Subject Classification Accuracy (Session 5)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cat_map = {v: k for k, v in test_ds.category_to_idx.items()}\n",
    "cat_names = [cat_map[i] for i in range(len(cat_map))]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm_norm, annot=False, fmt=\".2f\", cmap=\"Blues\", xticklabels=cat_names, yticklabels=cat_names)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
