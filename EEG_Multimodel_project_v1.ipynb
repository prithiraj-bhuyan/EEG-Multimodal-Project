{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9111d97",
   "metadata": {
    "_sphinx_cell_id": "0f98f313-c450-494f-9cbb-093c3eb59f83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class EEGMultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading the multimodal EEG, Image, and Text data.\n",
    "    \n",
    "    This version contains the fix for returning the 'category' for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 bids_root,          # Path to the .../ds005589/ directory\n",
    "                 images_dir,         # Path to the .../All_images/ directory\n",
    "                 captions_path,      # Path to the captions.txt file\n",
    "                 subject_list,       # List of subjects to load, e.g., ['sub-02', 'sub-03']\n",
    "                 session_list,       # List of sessions to load, e.g., ['ses-01', 'ses-02']\n",
    "                 image_transform=None, # PyTorch transforms for the images\n",
    "                 clamp_thres=500     # Clamping threshold for EEG in microvolts\n",
    "                ):\n",
    "        \n",
    "        self.bids_root = bids_root\n",
    "        self.images_dir = images_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.clamp_thres = clamp_thres\n",
    "\n",
    "        # 1. Initialize all 4 lists\n",
    "        self.all_eeg_trials = []\n",
    "        self.all_image_paths = []\n",
    "        self.all_captions = []\n",
    "        self.all_categories = [] # <-- For categories\n",
    "        \n",
    "        print(\"Initializing dataset... This may take a moment.\")\n",
    "        \n",
    "        print(f\"Loading captions from {captions_path}...\")\n",
    "        self.captions_dict = self._load_captions(captions_path)\n",
    "        print(f\"Loaded {len(self.captions_dict)} captions.\")\n",
    "\n",
    "        for sub in subject_list:\n",
    "            for ses in session_list:\n",
    "                for run in ['01', '02', '03', '04']:\n",
    "                    \n",
    "                    session_path = os.path.join(self.bids_root, sub, ses)\n",
    "                    csv_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_image.csv\")\n",
    "                    npy_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_1000Hz.npy\")\n",
    "                    \n",
    "                    if not (os.path.exists(csv_path) and os.path.exists(npy_path)):\n",
    "                        # print(f\"Warning: Missing files for {sub} {ses} {run}. Skipping.\")\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        csv_data = pd.read_csv(csv_path) \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading CSV {csv_path}: {e}. Skipping run.\")\n",
    "                        continue\n",
    "                    \n",
    "                    eeg_data = np.load(npy_path) \n",
    "                    \n",
    "                    if eeg_data.shape[0] != len(csv_data):\n",
    "                        print(f\"Warning: Trial mismatch in {sub} {ses} {run}. \"\n",
    "                              f\"EEG has {eeg_data.shape[0]}, CSV has {len(csv_data)}. Skipping.\")\n",
    "                        continue\n",
    "                        \n",
    "                    for i, row in csv_data.iterrows():\n",
    "                        \n",
    "                        img_base_name = self._get_base_name(row['FilePath']) \n",
    "                        if not img_base_name:\n",
    "                            continue\n",
    "                        \n",
    "                        category, caption = self.captions_dict.get(img_base_name, (\"Unknown\", \"No Caption\"))\n",
    "                        \n",
    "                        img_path = self._find_image_path(img_base_name)\n",
    "                        if not img_path:\n",
    "                            continue \n",
    "                            \n",
    "                        # 2. Append all 4 items in the loop\n",
    "                        self.all_eeg_trials.append(eeg_data[i])   \n",
    "                        self.all_image_paths.append(img_path)     \n",
    "                        self.all_captions.append(caption)         \n",
    "                        self.all_categories.append(category) # <-- *** THIS WAS THE FIX ***\n",
    "\n",
    "        print(f\"Found {len(self.all_eeg_trials)} total aligned trials.\")\n",
    "        \n",
    "        if len(self.all_eeg_trials) == 0:\n",
    "            print(\"ERROR: No trials were loaded. Check your BIDS_ROOT, IMAGE_DIR, and CAPTIONS_FILE paths.\")\n",
    "            self.eeg_dataset = np.array([])\n",
    "            self.image_paths = []\n",
    "            self.captions = []\n",
    "            self.categories = [] # 3. Store the (empty) list\n",
    "            return\n",
    "\n",
    "        eeg_dataset = np.array(self.all_eeg_trials, dtype=np.float32)\n",
    "        \n",
    "        # Clamp\n",
    "        eeg_dataset[eeg_dataset >  self.clamp_thres] =  self.clamp_thres\n",
    "        eeg_dataset[eeg_dataset < -self.clamp_thres] = -self.clamp_thres\n",
    "        \n",
    "        # Normalize\n",
    "        sample_num, time_num, channel_num = eeg_dataset.shape # <-- Corrected shape\n",
    "        eeg_dataset_flat = eeg_dataset.reshape(sample_num, -1)\n",
    "        \n",
    "        mean = np.mean(eeg_dataset_flat, axis=0)\n",
    "        std = np.std(eeg_dataset_flat, axis=0)\n",
    "        \n",
    "        eeg_dataset_flat = (eeg_dataset_flat - mean) / (std + 1e-6)\n",
    "        \n",
    "        self.eeg_dataset = eeg_dataset_flat.reshape(sample_num, time_num, channel_num)\n",
    "        \n",
    "        # 3. Store all 4 lists\n",
    "        self.image_paths = self.all_image_paths\n",
    "        self.captions = self.all_captions\n",
    "        self.categories = self.all_categories\n",
    "        \n",
    "        print(\"Dataset initialization complete.\")\n",
    "\n",
    "    def _load_captions(self, captions_path):\n",
    "            captions_dict = {}\n",
    "            with open(captions_path, 'r') as f:\n",
    "                next(f) # Skip header\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t') \n",
    "                    if len(parts) == 4:\n",
    "                        source, category, img_name, caption = parts\n",
    "                        captions_dict[img_name] = (category, caption)\n",
    "            return captions_dict\n",
    "\n",
    "    def _get_base_name(self, file_path):\n",
    "            try:\n",
    "                normalized_path = str(file_path).replace('\\\\', '/') \n",
    "                base_name_with_ext = os.path.basename(normalized_path) \n",
    "                base_name_resized = os.path.splitext(base_name_with_ext)[0]\n",
    "                \n",
    "                if base_name_resized.endswith('_resized'):\n",
    "                    base_name = base_name_resized[:-len('_resized')]\n",
    "                else:\n",
    "                    base_name = base_name_resized\n",
    "                return base_name \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in _get_base_name: {e}\")\n",
    "                return None\n",
    "\n",
    "    def _find_image_path(self, img_base_name):\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPEG']: \n",
    "            img_path = os.path.join(self.images_dir, img_base_name + ext)\n",
    "            if os.path.exists(img_path):\n",
    "                return img_path\n",
    "        return None \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Your dataloader gives [B, T, C] -> [32, 500, 122]\n",
    "        # We need to swap this for Conv1D models\n",
    "        eeg_data = self.eeg_dataset[idx] # Shape [500, 122]\n",
    "        eeg_tensor = torch.tensor(eeg_data).float()\n",
    "        \n",
    "        caption = self.captions[idx] \n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.image_transform:\n",
    "                image_tensor = self.image_transform(image)\n",
    "            else:\n",
    "                image_tensor = transforms.ToTensor()(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}. Returning a dummy image.\")\n",
    "            image_tensor = torch.zeros(3, 224, 224) \n",
    "\n",
    "        # 4. Return all 4 items\n",
    "        category = self.categories[idx]\n",
    "        return eeg_tensor, image_tensor, caption, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bd3f27",
   "metadata": {
    "_sphinx_cell_id": "4ae854a8-d47e-460f-b06c-8bec4ab7c424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Training Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 15600 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Creating Validation Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 5200 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Creating Test Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 5200 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Testing the training loader...\n",
      "EEG batch shape:   torch.Size([32, 500, 122])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Caption batch (first item): 'Cow standing on grass behind wire fence'\n",
      "Category batch (first item): 'cow'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --- 1. Define Your Paths ---\n",
    "# (Update these paths to match your system)\n",
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "\n",
    "# --- 2. Define Your Subject List ---\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "\n",
    "# --- 3. Define Image Transforms (e.g., for CLIP) ---\n",
    "# (You would get the specific transforms from your model)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 4. Create the 3 Datasets (Train/Val/Test) ---\n",
    "# This perfectly follows the paper's \"split by session\" rule.\n",
    "\n",
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], # 3 sessions for training\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Validation Dataset...\")\n",
    "val_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-04'], # 1 session for validation\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Test Dataset...\")\n",
    "test_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-05'], # 1 session for testing\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "# --- 5. Create PyTorch DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- 6. Test the loader ---\n",
    "print(\"\\nTesting the training loader...\")\n",
    "eeg_batch, image_batch, caption_batch, category_batch = next(iter(train_loader)) \n",
    "\n",
    "print(f\"EEG batch shape:   {eeg_batch.shape}\")\n",
    "print(f\"Image batch shape: {image_batch.shape}\")\n",
    "print(f\"Caption batch (first item): '{caption_batch[0]}'\")\n",
    "print(f\"Category batch (first item): '{category_batch[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ebc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ocean/projects/cis250019p/mzhang23/TA/HW3P2/envs/hw3p2_env/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/ocean/projects/cis250019p/mzhang23/TA/HW3P2/envs/hw3p2_env/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /jet/home/pbhuyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpbhuyan\u001b[0m (\u001b[33mpbhuyan-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Building class-to-index mapping...\n",
      "Found 20 unique classes.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb  # <-- Import W&B\n",
    "\n",
    "# --- Login to W&B Automatically ---\n",
    "# Hardcoding your API key for automatic login\n",
    "wandb.login(key=\"be570aff6d4f4fd5239571214e49fb3e718f29c8\")\n",
    "\n",
    "# --- Define Device ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Build Class Label Mapping ---\n",
    "print(\"Building class-to-index mapping...\")\n",
    "all_cats = sorted(list(set(train_dataset.categories)))\n",
    "num_classes = len(all_cats)\n",
    "label_to_index = {label: i for i, label in enumerate(all_cats)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "print(f\"Found {num_classes} unique classes.\")\n",
    "\n",
    "\n",
    "# --- Model Definitions (from repo, fixed) ---\n",
    "\n",
    "class ModelFC(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(ModelFC, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.BatchNorm1d(num_features=hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, out_dim),\n",
    "            # nn.Softmax(dim=-1) # <-- DELETED (This is the critical bug fix)\n",
    "        )  \n",
    "    def forward(self, x):\n",
    "        # x shape is [bs, time, electrode] -> [32, 500, 122]\n",
    "        # Flatten for FC layer\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        return self.model(x_flat)\n",
    "\n",
    "class ModelConv(nn.Module):\n",
    "    def __init__(self, electrode_num=122, class_num=20,\n",
    "                 ch1=128, ch2=256, ch3=512, \n",
    "                 kernal1=3, kernal2=3, kernal3=3):  \n",
    "        super(ModelConv, self).__init__()     \n",
    "        \n",
    "        self.model_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=electrode_num, out_channels=ch1, kernel_size=kernal1),\n",
    "            nn.BatchNorm1d(num_features=ch1), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=ch1, out_channels=ch2, kernel_size=kernal2),\n",
    "            nn.BatchNorm1d(num_features=ch2), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=ch2, out_channels=ch3, kernel_size=kernal3),\n",
    "            nn.BatchNorm1d(num_features=ch3), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # --- FIX: Calculate fc_in_dim automatically ---\n",
    "        dummy_input = torch.randn(1, 500, electrode_num) # (1, 500, 122)\n",
    "        dummy_transposed = dummy_input.transpose(dim0=1, dim1=2) # (1, 122, 500)\n",
    "        conv_out = self.model_conv(dummy_transposed)\n",
    "        fc_in_dim = conv_out.reshape(1, -1).shape[1]\n",
    "        print(f\"ModelConv: Calculated fc_in_dim = {fc_in_dim}\")\n",
    "        # --- End Fix ---\n",
    "\n",
    "        self.model_fc = nn.Sequential(\n",
    "            nn.Linear(fc_in_dim, class_num),\n",
    "            # nn.Softmax(dim=-1) # <-- DELETED\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_transpose = x.transpose(dim0=1, dim1=2) # -> [32, 122, 500]\n",
    "        conv_out = self.model_conv(x_transpose)\n",
    "        bs = conv_out.shape[0]\n",
    "        fc_in = conv_out.reshape([bs,-1])\n",
    "        return self.model_fc(fc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a66404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_loss</td><td>█▄▁</td></tr><tr><td>val_accuracy</td><td>▃█▁</td></tr><tr><td>val_loss</td><td>▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>2.85374</td></tr><tr><td>val_accuracy</td><td>0.07673</td></tr><tr><td>val_loss</td><td>3.01146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">modelfc_baseline_run_1</strong> at: <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1</a><br> View project at: <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_153418-modelfc_baseline_run_1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/jet/home/pbhuyan/wandb/run-20251026_153705-modelfc_baseline_run_1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">modelfc_baseline_run_1</a></strong> to <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming run modelfc_baseline_run_1...\n",
      "Attempting to load checkpoint from: ./modelfc_baseline_run_1.pth\n",
      "Resumed successfully. Starting from epoch 3\n",
      "--- Starting Training for ModelFC_baseline from Epoch 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18883c038cfd422f98a1b4e5dbaf6a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/97 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0200b26a33dd47a9953aa5aae2c86d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 004 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d07b66367f4f8eb3f531094baa2526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 004 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7b2f5ba4474a6483ffad419d36595c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 005 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e19317742145a4aec0f1c48b094cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 005 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7023dc3311ab48f8bef219de6d09d4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 006 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3120b5dd0ec74c43b5d22d02b85bbc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 006 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d14c573e18455ba69a12651f8b1bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 007 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cb4969e8534e4ab2531e0f0809755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 007 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f548b02b744549d0a50f2c06dd97c01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 008 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38729e617cb4bd2b5fde9594a733594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 008 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0d0b55ce294d589a64f053760165b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 009 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b75414deb8498a8050b5b8d59f6e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 009 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5551cefdf04e30807ddd266dab1af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 010 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd7b4b99a37402d95491c3d1dd6167a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 010 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee4fdd73c9a4d1a93f916ec8df43414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 011 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ce70b9dc0a46188177d9545beba7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 011 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f6bd7c879d40b78c09a3fcfd337e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 012 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ec823a46d44e629314dd8ff0aa5d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 012 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80738e7463cf48f6915f99351d4669f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 013 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdd461156d1480db7a425eb95898648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 013 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6b1cf5ee7e4eb681d90eaa54c056ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 014 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee7be3e04724ab59e55d3aea53e3c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 014 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b370a2c8e6434ba283451cd616e1049c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 015 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ede87ae1264a35a1b4afc102ba23d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 015 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5366ced94adc4a11b0d092d466e9d606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 016 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389787d7069f4c2bb4054e854519cd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 016 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4d7ec1584c46ccb9fd2d097e1078f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 017 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080693c6840148f0a2b550ad471ff873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 017 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558e3d4c1a8c444db79200d7abc333c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 018 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5310868a9d4335b45a5a3f4b29be44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 018 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c440c05a4b3b47a0b824273d8c4cb84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 019 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeede76b95c46d9a306e711bb3cbc49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 019 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403613cdcec448439826e40b6983b4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 020 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffe15eb5f834c7a85ee5330c4a7a216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 020 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb88d393b1d417592b905bcaf6aca6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 021 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e52a1f57a04467d90f2ea9aeca5a6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 021 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c957c5256e4667a7c9061c772b938d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 022 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dd515ed1a84212b647d503a55d5b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 022 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037ef9b355b44b06b8359a555e021115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 023 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04b141e6cd34c2a86eb866713986770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 023 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e8e01de32545198c943d24ac27e6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 024 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94472cddfbb4aec831cc6d5f43f1947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 024 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dabce3f3ad34870b98a0a88f921ca76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 025 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1a3b969e404d39a7dde07edb6c1c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 025 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f13e11bb4e94bd3b9f628b875132667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 026 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8143f1fb5e2c4b3197af24ce735f8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 026 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6372a6c63d8b4a719973fc410d6a8a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 027 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f60c05f513417fb86deba9eea157f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 027 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe930edd0fc4fdd85eda380957d7364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 028 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd79e5e34e2445d29e7aeaade7036296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 028 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f984a93e53004ec0bcd28f7a3cb78696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 029 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ed7a723d04cac98bb5a335d2e4a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 029 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cf07dd68c4415fa75dd1e04dc1faf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 030 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c96dcb8cb54f8bb4428a35b52e6d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 030 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e41f932c07b4aac9c1bd198c856ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 031 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9533c7364b0f4e68939c7672b177de80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 031 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d32f62f0137450a874a6168014a77f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 032 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beae8b5a91f45308a5e1306f29be3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 032 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b8eee71a304f928f631b4263961965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 033 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab8db44e21a4d8fb381de337cbb0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 033 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73a1d9e1b0043768d83f3b81a15a1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 034 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91feeaa9f4d48f7ad17a61d9c4eacb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 034 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1264266270324c87bdee516ce28c72f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 035 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51607bbcd6d14dafb23b888896ffe0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 035 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f66132ad647508f19b1911e059fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 036 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207c0018e9134266b5b4b1d0e3399fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 036 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdc145511d2478c8da003390648911f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 037 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccd117d43aa4172835f4c5e8d3f2ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 037 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a295b61c91a4f66bc207ba893ea9318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 038 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8702a88424b943c5b732e73fd96b91e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 038 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcebd01f34549918b2ca6f30a6f061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 039 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086e35662ffa4497b9d38da97b135c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 039 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ef8cd284f54f48ab14df91e67b948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 040 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Task 1: Train ModelFC Baseline with W&B ---\n",
    "\n",
    "# --- 1. Define Run Configuration ---\n",
    "# All hyperparameters go here\n",
    "config = {\n",
    "    \"model_name\": \"ModelFC_baseline\",\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 5e-5,\n",
    "    \"batch_size\": 32,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"in_dim\": 500 * 122,\n",
    "    \"num_classes\": num_classes,\n",
    "}\n",
    "\n",
    "# Define a unique ID for this run, so you can resume it\n",
    "RUN_ID = \"modelfc_baseline_run_1\"\n",
    "CKPT_PATH = f\"./{RUN_ID}.pth\"\n",
    "\n",
    "# --- 2. Initialize W&B ---\n",
    "run = wandb.init(\n",
    "    project=\"eeg-classification\", # Name of your project\n",
    "    job_type=\"train\",\n",
    "    config=config,\n",
    "    id=RUN_ID,        # Set a fixed ID for this run\n",
    "    resume=\"allow\",   # Allow resuming if this ID exists\n",
    ")\n",
    "\n",
    "# --- 3. Instantiate Model, Optimizer, Loss ---\n",
    "model_fc = ModelFC(config[\"in_dim\"], config[\"hidden_dim\"], config[\"num_classes\"]).to(DEVICE)\n",
    "optimizer = optim.Adam(model_fc.parameters(), lr=config[\"lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- 4. Load Checkpoint if Resuming ---\n",
    "start_epoch = 0\n",
    "if wandb.run.resumed:\n",
    "    print(f\"Resuming run {RUN_ID}...\")\n",
    "    try:\n",
    "        print(f\"Attempting to load checkpoint from: {CKPT_PATH}\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        model_fc.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resumed successfully. Starting from epoch {start_epoch}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No checkpoint file found. Starting from scratch.\")\n",
    "    # --- THIS BLOCK WAS MOVED INSIDE THE 'if' STATEMENT ---\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "\n",
    "# Tell W&B to watch the model\n",
    "wandb.watch(model_fc, criterion, log=\"all\", log_freq=100)\n",
    "\n",
    "# --- 5. Training Loop ---\n",
    "print(f\"--- Starting Training for {config['model_name']} from Epoch {start_epoch+1} ---\")\n",
    "\n",
    "# Outer progress bar for epochs\n",
    "epoch_bar = tqdm(range(start_epoch, config[\"epochs\"]), desc=\"Epochs\")\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    model_fc.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1:03} Training\", leave=False)\n",
    "    \n",
    "    for eeg_batch, _, _, category_batch in train_bar: \n",
    "        eeg_batch = eeg_batch.to(DEVICE)\n",
    "        labels = torch.tensor([label_to_index[cat] for cat in category_batch], dtype=torch.long).to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model_fc(eeg_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model_fc.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1:03} Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg_batch, _, _, category_batch in val_bar:\n",
    "            eeg_batch = eeg_batch.to(DEVICE)\n",
    "            labels = torch.tensor([label_to_index[cat] for cat in category_batch], dtype=torch.long).to(DEVICE)\n",
    "            \n",
    "            logits = model_fc(eeg_batch)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # --- 6. Log Metrics to W&B ---\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": val_accuracy\n",
    "    })\n",
    "    \n",
    "    # Update the main epoch bar\n",
    "    epoch_bar.set_postfix(\n",
    "        Train_Loss=f\"{avg_train_loss:.4f}\", \n",
    "        Val_Loss=f\"{avg_val_loss:.4f}\", \n",
    "        Val_Acc=f\"{val_accuracy*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # --- 7. Save Checkpoint ---\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_fc.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_val_loss,\n",
    "    }, CKPT_PATH)\n",
    "\n",
    "# --- 8. Finish the W&B Run ---\n",
    "wandb.finish()\n",
    "print(f\"--- {config['model_name']} training complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (idl_hw3p2)",
   "language": "python",
   "name": "hw3p2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
