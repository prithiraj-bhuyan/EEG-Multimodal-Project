{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d2c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: pandas in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: torch in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: torchvision in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.24.0)\n",
      "Requirement already satisfied: Pillow in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (12.0.0)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 6))\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Collecting wandb (from -r requirements.txt (line 8))\n",
      "  Downloading wandb-0.22.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (4.57.1)\n",
      "Requirement already satisfied: peft in ./eeg-env/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./eeg-env/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./eeg-env/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./eeg-env/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: filelock in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in ./eeg-env/lib/python3.12/site-packages (from torch->-r requirements.txt (line 3)) (3.5.0)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Downloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.1 (from wandb->-r requirements.txt (line 8))\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 8))\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in ./eeg-env/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: platformdirs in ./eeg-env/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 8)) (4.5.0)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb->-r requirements.txt (line 8))\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb->-r requirements.txt (line 8))\n",
      "  Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Requirement already satisfied: pyyaml in ./eeg-env/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 8)) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./eeg-env/lib/python3.12/site-packages (from wandb->-r requirements.txt (line 8)) (2.32.5)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb->-r requirements.txt (line 8))\n",
      "  Downloading sentry_sdk-2.42.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./eeg-env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 9)) (0.36.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./eeg-env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 9)) (2025.10.23)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./eeg-env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 9)) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./eeg-env/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 9)) (0.6.2)\n",
      "Requirement already satisfied: psutil in ./eeg-env/lib/python3.12/site-packages (from peft->-r requirements.txt (line 10)) (7.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./eeg-env/lib/python3.12/site-packages (from peft->-r requirements.txt (line 10)) (1.11.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./eeg-env/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 9)) (1.2.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "  Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3->wandb->-r requirements.txt (line 8))\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./eeg-env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./eeg-env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./eeg-env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./eeg-env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./eeg-env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 8)) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./eeg-env/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./eeg-env/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 8))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.22.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.42.1-py2.py3-none-any.whl (380 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: typing-inspection, threadpoolctl, smmap, sentry-sdk, scipy, pydantic-core, protobuf, joblib, click, annotated-types, scikit-learn, pydantic, gitdb, gitpython, wandb\n",
      "Successfully installed annotated-types-0.7.0 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 joblib-1.5.2 protobuf-6.33.0 pydantic-2.12.3 pydantic-core-2.41.4 scikit-learn-1.7.2 scipy-1.16.2 sentry-sdk-2.42.1 smmap-5.0.2 threadpoolctl-3.6.0 typing-inspection-0.4.2 wandb-0.22.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9111d97",
   "metadata": {
    "_sphinx_cell_id": "0f98f313-c450-494f-9cbb-093c3eb59f83"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class EEGMultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading the multimodal EEG, Image, and Text data.\n",
    "    \n",
    "    This version contains the fix for returning the 'category' for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 bids_root,          # Path to the .../ds005589/ directory\n",
    "                 images_dir,         # Path to the .../All_images/ directory\n",
    "                 captions_path,      # Path to the captions.txt file\n",
    "                 subject_list,       # List of subjects to load, e.g., ['sub-02', 'sub-03']\n",
    "                 session_list,       # List of sessions to load, e.g., ['ses-01', 'ses-02']\n",
    "                 image_transform=None, # PyTorch transforms for the images\n",
    "                 clamp_thres=500     # Clamping threshold for EEG in microvolts\n",
    "                ):\n",
    "        \n",
    "        self.bids_root = bids_root\n",
    "        self.images_dir = images_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.clamp_thres = clamp_thres\n",
    "\n",
    "        # 1. Initialize all 4 lists\n",
    "        self.all_eeg_trials = []\n",
    "        self.all_image_paths = []\n",
    "        self.all_captions = []\n",
    "        self.all_categories = [] # <-- For categories\n",
    "        \n",
    "        print(\"Initializing dataset... This may take a moment.\")\n",
    "        \n",
    "        print(f\"Loading captions from {captions_path}...\")\n",
    "        self.captions_dict = self._load_captions(captions_path)\n",
    "        print(f\"Loaded {len(self.captions_dict)} captions.\")\n",
    "\n",
    "        for sub in subject_list:\n",
    "            for ses in session_list:\n",
    "                for run in ['01', '02', '03', '04']:\n",
    "                    \n",
    "                    session_path = os.path.join(self.bids_root, sub, ses)\n",
    "                    csv_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_image.csv\")\n",
    "                    npy_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_1000Hz.npy\")\n",
    "                    \n",
    "                    if not (os.path.exists(csv_path) and os.path.exists(npy_path)):\n",
    "                        # print(f\"Warning: Missing files for {sub} {ses} {run}. Skipping.\")\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        csv_data = pd.read_csv(csv_path) \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading CSV {csv_path}: {e}. Skipping run.\")\n",
    "                        continue\n",
    "                    \n",
    "                    eeg_data = np.load(npy_path) \n",
    "                    \n",
    "                    if eeg_data.shape[0] != len(csv_data):\n",
    "                        print(f\"Warning: Trial mismatch in {sub} {ses} {run}. \"\n",
    "                              f\"EEG has {eeg_data.shape[0]}, CSV has {len(csv_data)}. Skipping.\")\n",
    "                        continue\n",
    "                        \n",
    "                    for i, row in csv_data.iterrows():\n",
    "                        \n",
    "                        img_base_name = self._get_base_name(row['FilePath']) \n",
    "                        if not img_base_name:\n",
    "                            continue\n",
    "                        \n",
    "                        category, caption = self.captions_dict.get(img_base_name, (\"Unknown\", \"No Caption\"))\n",
    "                        \n",
    "                        img_path = self._find_image_path(img_base_name)\n",
    "                        if not img_path:\n",
    "                            continue \n",
    "                            \n",
    "                        # 2. Append all 4 items in the loop\n",
    "                        self.all_eeg_trials.append(eeg_data[i])   \n",
    "                        self.all_image_paths.append(img_path)     \n",
    "                        self.all_captions.append(caption)         \n",
    "                        self.all_categories.append(category) # <-- *** THIS WAS THE FIX ***\n",
    "\n",
    "        print(f\"Found {len(self.all_eeg_trials)} total aligned trials.\")\n",
    "        \n",
    "        if len(self.all_eeg_trials) == 0:\n",
    "            print(\"ERROR: No trials were loaded. Check your BIDS_ROOT, IMAGE_DIR, and CAPTIONS_FILE paths.\")\n",
    "            self.eeg_dataset = np.array([])\n",
    "            self.image_paths = []\n",
    "            self.captions = []\n",
    "            self.categories = [] # 3. Store the (empty) list\n",
    "            return\n",
    "\n",
    "        eeg_dataset = np.array(self.all_eeg_trials, dtype=np.float32)\n",
    "        \n",
    "        # Clamp\n",
    "        eeg_dataset[eeg_dataset >  self.clamp_thres] =  self.clamp_thres\n",
    "        eeg_dataset[eeg_dataset < -self.clamp_thres] = -self.clamp_thres\n",
    "        \n",
    "        # Normalize\n",
    "        sample_num, time_num, channel_num = eeg_dataset.shape # <-- Corrected shape\n",
    "        eeg_dataset_flat = eeg_dataset.reshape(sample_num, -1)\n",
    "        \n",
    "        mean = np.mean(eeg_dataset_flat, axis=0)\n",
    "        std = np.std(eeg_dataset_flat, axis=0)\n",
    "        \n",
    "        eeg_dataset_flat = (eeg_dataset_flat - mean) / (std + 1e-6)\n",
    "        \n",
    "        self.eeg_dataset = eeg_dataset_flat.reshape(sample_num, time_num, channel_num)\n",
    "        \n",
    "        # 3. Store all 4 lists\n",
    "        self.image_paths = self.all_image_paths\n",
    "        self.captions = self.all_captions\n",
    "        self.categories = self.all_categories\n",
    "        \n",
    "        print(\"Dataset initialization complete.\")\n",
    "\n",
    "    def _load_captions(self, captions_path):\n",
    "            captions_dict = {}\n",
    "            with open(captions_path, 'r') as f:\n",
    "                next(f) # Skip header\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t') \n",
    "                    if len(parts) == 4:\n",
    "                        source, category, img_name, caption = parts\n",
    "                        captions_dict[img_name] = (category, caption)\n",
    "            return captions_dict\n",
    "\n",
    "    def _get_base_name(self, file_path):\n",
    "            try:\n",
    "                normalized_path = str(file_path).replace('\\\\', '/') \n",
    "                base_name_with_ext = os.path.basename(normalized_path) \n",
    "                base_name_resized = os.path.splitext(base_name_with_ext)[0]\n",
    "                \n",
    "                if base_name_resized.endswith('_resized'):\n",
    "                    base_name = base_name_resized[:-len('_resized')]\n",
    "                else:\n",
    "                    base_name = base_name_resized\n",
    "                return base_name \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR in _get_base_name: {e}\")\n",
    "                return None\n",
    "\n",
    "    def _find_image_path(self, img_base_name):\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPEG']: \n",
    "            img_path = os.path.join(self.images_dir, img_base_name + ext)\n",
    "            if os.path.exists(img_path):\n",
    "                return img_path\n",
    "        return None \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Your dataloader gives [B, T, C] -> [32, 500, 122]\n",
    "        # We need to swap this for Conv1D models\n",
    "        eeg_data = self.eeg_dataset[idx] # Shape [500, 122]\n",
    "        eeg_tensor = torch.tensor(eeg_data).float()\n",
    "        \n",
    "        caption = self.captions[idx] \n",
    "        img_path = self.image_paths[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.image_transform:\n",
    "                image_tensor = self.image_transform(image)\n",
    "            else:\n",
    "                image_tensor = transforms.ToTensor()(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}. Returning a dummy image.\")\n",
    "            image_tensor = torch.zeros(3, 224, 224) \n",
    "\n",
    "        # 4. Return all 4 items\n",
    "        category = self.categories[idx]\n",
    "        return eeg_tensor, image_tensor, caption, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bd3f27",
   "metadata": {
    "_sphinx_cell_id": "4ae854a8-d47e-460f-b06c-8bec4ab7c424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Training Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 15600 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Creating Validation Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 5200 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Creating Test Dataset...\n",
      "Initializing dataset... This may take a moment.\n",
      "Loading captions from /ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt...\n",
      "Loaded 9825 captions.\n",
      "Found 5200 total aligned trials.\n",
      "Dataset initialization complete.\n",
      "\n",
      "Testing the training loader...\n",
      "EEG batch shape:   torch.Size([32, 500, 122])\n",
      "Image batch shape: torch.Size([32, 3, 224, 224])\n",
      "Caption batch (first item): 'Diningtable with checkered cloth and dishes'\n",
      "Category batch (first item): 'diningtable'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --- 1. Define Your Paths ---\n",
    "# (Update these paths to match your system)\n",
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "\n",
    "# --- 2. Define Your Subject List ---\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "\n",
    "# --- 3. Define Image Transforms (e.g., for CLIP) ---\n",
    "# (You would get the specific transforms from your model)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- 4. Create the 3 Datasets (Train/Val/Test) ---\n",
    "# This perfectly follows the paper's \"split by session\" rule.\n",
    "\n",
    "print(\"Creating Training Dataset...\")\n",
    "train_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], # 3 sessions for training\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Validation Dataset...\")\n",
    "val_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-04'], # 1 session for validation\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "print(\"\\nCreating Test Dataset...\")\n",
    "test_dataset = EEGMultimodalDataset(\n",
    "    bids_root=BIDS_ROOT,\n",
    "    images_dir=IMAGE_DIR,\n",
    "    captions_path=CAPTIONS_FILE,\n",
    "    subject_list=ALL_SUBJECTS,\n",
    "    session_list=['ses-05'], # 1 session for testing\n",
    "    image_transform=image_transforms\n",
    ")\n",
    "\n",
    "# --- 5. Create PyTorch DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# --- 6. Test the loader ---\n",
    "print(\"\\nTesting the training loader...\")\n",
    "eeg_batch, image_batch, caption_batch, category_batch = next(iter(train_loader)) \n",
    "\n",
    "print(f\"EEG batch shape:   {eeg_batch.shape}\")\n",
    "print(f\"Image batch shape: {image_batch.shape}\")\n",
    "print(f\"Caption batch (first item): '{caption_batch[0]}'\")\n",
    "print(f\"Category batch (first item): '{category_batch[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ebc141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/pbhuyan/eeg-env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/jet/home/pbhuyan/eeg-env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /jet/home/pbhuyan/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpbhuyan\u001b[0m (\u001b[33mpbhuyan-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Building class-to-index mapping...\n",
      "Found 20 unique classes.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb  # <-- Import W&B\n",
    "\n",
    "# --- Login to W&B Automatically ---\n",
    "# Hardcoding your API key for automatic login\n",
    "wandb.login(key=\"be570aff6d4f4fd5239571214e49fb3e718f29c8\")\n",
    "\n",
    "# --- Define Device ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Build Class Label Mapping ---\n",
    "print(\"Building class-to-index mapping...\")\n",
    "all_cats = sorted(list(set(train_dataset.categories)))\n",
    "num_classes = len(all_cats)\n",
    "label_to_index = {label: i for i, label in enumerate(all_cats)}\n",
    "index_to_label = {i: label for label, i in label_to_index.items()}\n",
    "print(f\"Found {num_classes} unique classes.\")\n",
    "\n",
    "\n",
    "# --- Model Definitions (from repo, fixed) ---\n",
    "\n",
    "class ModelFC(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(ModelFC, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim),\n",
    "            nn.BatchNorm1d(num_features=hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim, out_dim),\n",
    "            # nn.Softmax(dim=-1) # <-- DELETED (This is the critical bug fix)\n",
    "        )  \n",
    "    def forward(self, x):\n",
    "        # x shape is [bs, time, electrode] -> [32, 500, 122]\n",
    "        # Flatten for FC layer\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        return self.model(x_flat)\n",
    "\n",
    "class ModelConv(nn.Module):\n",
    "    def __init__(self, electrode_num=122, class_num=20,\n",
    "                 ch1=128, ch2=256, ch3=512, \n",
    "                 kernal1=3, kernal2=3, kernal3=3):  \n",
    "        super(ModelConv, self).__init__()     \n",
    "        \n",
    "        self.model_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=electrode_num, out_channels=ch1, kernel_size=kernal1),\n",
    "            nn.BatchNorm1d(num_features=ch1), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=ch1, out_channels=ch2, kernel_size=kernal2),\n",
    "            nn.BatchNorm1d(num_features=ch2), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=ch2, out_channels=ch3, kernel_size=kernal3),\n",
    "            nn.BatchNorm1d(num_features=ch3), nn.ReLU(),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        # --- FIX: Calculate fc_in_dim automatically ---\n",
    "        dummy_input = torch.randn(1, 500, electrode_num) # (1, 500, 122)\n",
    "        dummy_transposed = dummy_input.transpose(dim0=1, dim1=2) # (1, 122, 500)\n",
    "        conv_out = self.model_conv(dummy_transposed)\n",
    "        fc_in_dim = conv_out.reshape(1, -1).shape[1]\n",
    "        print(f\"ModelConv: Calculated fc_in_dim = {fc_in_dim}\")\n",
    "        # --- End Fix ---\n",
    "\n",
    "        self.model_fc = nn.Sequential(\n",
    "            nn.Linear(fc_in_dim, class_num),\n",
    "            # nn.Softmax(dim=-1) # <-- DELETED\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_transpose = x.transpose(dim0=1, dim1=2) # -> [32, 122, 500]\n",
    "        conv_out = self.model_conv(x_transpose)\n",
    "        bs = conv_out.shape[0]\n",
    "        fc_in = conv_out.reshape([bs,-1])\n",
    "        return self.model_fc(fc_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a66404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/jet/home/pbhuyan/wandb/run-20251026_165424-modelfc_baseline_run_1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">modelfc_baseline_run_1</a></strong> to <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming run modelfc_baseline_run_1...\n",
      "Attempting to load checkpoint from: ./modelfc_baseline_run_1.pth\n",
      "Resumed successfully. Starting from epoch 100\n",
      "--- Starting Training for ModelFC_baseline from Epoch 101 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fce6e4af294be8acfb1dcaa5e9427f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>train_loss</td><td>0.40934</td></tr><tr><td>val_accuracy</td><td>0.07</td></tr><tr><td>val_loss</td><td>4.75222</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">modelfc_baseline_run_1</strong> at: <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification/runs/modelfc_baseline_run_1</a><br> View project at: <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251026_165424-modelfc_baseline_run_1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ModelFC_baseline training complete. ---\n"
     ]
    }
   ],
   "source": [
    "# --- Task 1: Train ModelFC Baseline with W&B ---\n",
    "\n",
    "# --- 1. Define Run Configuration ---\n",
    "# All hyperparameters go here\n",
    "config = {\n",
    "    \"model_name\": \"ModelFC_baseline\",\n",
    "    \"epochs\": 1,\n",
    "    \"lr\": 5e-5,\n",
    "    \"batch_size\": 32,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"in_dim\": 500 * 122,\n",
    "    \"num_classes\": num_classes,\n",
    "}\n",
    "\n",
    "# Define a unique ID for this run, so you can resume it\n",
    "RUN_ID = \"modelfc_baseline_run_1\"\n",
    "CKPT_PATH = f\"./{RUN_ID}.pth\"\n",
    "\n",
    "# --- 2. Initialize W&B ---\n",
    "run = wandb.init(\n",
    "    project=\"eeg-classification\", # Name of your project\n",
    "    job_type=\"train\",\n",
    "    config=config,\n",
    "    id=RUN_ID,        # Set a fixed ID for this run\n",
    "    resume=\"allow\",   # Allow resuming if this ID exists\n",
    ")\n",
    "\n",
    "# --- 3. Instantiate Model, Optimizer, Loss ---\n",
    "model_fc = ModelFC(config[\"in_dim\"], config[\"hidden_dim\"], config[\"num_classes\"]).to(DEVICE)\n",
    "optimizer = optim.Adam(model_fc.parameters(), lr=config[\"lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- 4. Load Checkpoint if Resuming ---\n",
    "start_epoch = 0\n",
    "if wandb.run.resumed:\n",
    "    print(f\"Resuming run {RUN_ID}...\")\n",
    "    try:\n",
    "        print(f\"Attempting to load checkpoint from: {CKPT_PATH}\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        model_fc.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(f\"Resumed successfully. Starting from epoch {start_epoch}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No checkpoint file found. Starting from scratch.\")\n",
    "    # --- THIS BLOCK WAS MOVED INSIDE THE 'if' STATEMENT ---\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "\n",
    "# Tell W&B to watch the model\n",
    "wandb.watch(model_fc, criterion, log=\"all\", log_freq=100)\n",
    "\n",
    "# --- 5. Training Loop ---\n",
    "print(f\"--- Starting Training for {config['model_name']} from Epoch {start_epoch+1} ---\")\n",
    "\n",
    "# Outer progress bar for epochs\n",
    "epoch_bar = tqdm(range(start_epoch, config[\"epochs\"]), desc=\"Epochs\")\n",
    "\n",
    "for epoch in epoch_bar:\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    model_fc.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1:03} Training\", leave=False)\n",
    "    \n",
    "    for eeg_batch, _, _, category_batch in train_bar: \n",
    "        eeg_batch = eeg_batch.to(DEVICE)\n",
    "        labels = torch.tensor([label_to_index[cat] for cat in category_batch], dtype=torch.long).to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model_fc(eeg_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model_fc.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1:03} Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg_batch, _, _, category_batch in val_bar:\n",
    "            eeg_batch = eeg_batch.to(DEVICE)\n",
    "            labels = torch.tensor([label_to_index[cat] for cat in category_batch], dtype=torch.long).to(DEVICE)\n",
    "            \n",
    "            logits = model_fc(eeg_batch)\n",
    "            loss = criterion(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # --- 6. Log Metrics to W&B ---\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": val_accuracy\n",
    "    })\n",
    "    \n",
    "    # Update the main epoch bar\n",
    "    epoch_bar.set_postfix(\n",
    "        Train_Loss=f\"{avg_train_loss:.4f}\", \n",
    "        Val_Loss=f\"{avg_val_loss:.4f}\", \n",
    "        Val_Acc=f\"{val_accuracy*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # --- 7. Save Checkpoint ---\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_fc.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_val_loss,\n",
    "    }, CKPT_PATH)\n",
    "\n",
    "# --- 8. Finish the W&B Run ---\n",
    "wandb.finish()\n",
    "print(f\"--- {config['model_name']} training complete. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9251268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./eeg-env/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./eeg-env/lib/python3.12/site-packages (from ipywidgets) (9.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./eeg-env/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./eeg-env/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./eeg-env/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./eeg-env/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./eeg-env/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./eeg-env/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./eeg-env/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./eeg-env/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d74e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP model...\n",
      "CLIP model loaded and frozen.\n",
      "Calculating image and text embeddings for the validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eb7056423a4dd6918faec1abd151a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Embeddings:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished calculating embeddings.\n",
      "Image embeds shape: torch.Size([5200, 512])\n",
      "Text embeds shape:  torch.Size([5200, 512])\n",
      "\n",
      "Calculating retrieval accuracy...\n",
      "\n",
      "--- CLIP Baseline Results (Image-to-Text Retrieval on Validation Set) ---\n",
      "Recall@1 : 21.96%\n",
      "Recall@5 : 49.87%\n",
      "Recall@10: 61.37%\n"
     ]
    }
   ],
   "source": [
    "# --- Task 2a: Image-Caption Retrieval Baseline ---\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# 1. Load frozen CLIP Model and Processor\n",
    "print(\"Loading CLIP model...\")\n",
    "clip_model_name = \"openai/clip-vit-base-patch32\"\n",
    "clip_model = CLIPModel.from_pretrained(clip_model_name).to(DEVICE)\n",
    "clip_processor = CLIPProcessor.from_pretrained(clip_model_name)\n",
    "\n",
    "# Ensure the model is frozen and in evaluation mode\n",
    "clip_model.eval()\n",
    "for param in clip_model.parameters():\n",
    "    param.requires_grad = False\n",
    "print(\"CLIP model loaded and frozen.\")\n",
    "\n",
    "# 2. Calculate Embeddings for the Validation Set\n",
    "# We'll store all image and text embeddings from the val_loader\n",
    "all_img_embeds = []\n",
    "all_txt_embeds = []\n",
    "print(\"Calculating image and text embeddings for the validation set...\")\n",
    "\n",
    "# Use tqdm for progress\n",
    "val_embed_bar = tqdm(val_loader, desc=\"Calculating Embeddings\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Note: We only need image_batch and caption_batch here\n",
    "    for _, image_batch, caption_batch, _ in val_embed_bar: \n",
    "        \n",
    "        image_batch = image_batch.to(DEVICE)\n",
    "        \n",
    "        # Process text captions using the CLIP processor\n",
    "        # Important: Convert tuple of captions to a list for the processor\n",
    "        text_inputs = clip_processor(\n",
    "            text=list(caption_batch), \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        # Get embeddings from CLIP\n",
    "        img_embeds = clip_model.get_image_features(image_batch)\n",
    "        txt_embeds = clip_model.get_text_features(**text_inputs)\n",
    "        \n",
    "        # Normalize embeddings (standard practice for CLIP similarity)\n",
    "        img_embeds /= img_embeds.norm(dim=-1, keepdim=True)\n",
    "        txt_embeds /= txt_embeds.norm(dim=-1, keepdim=True)\n",
    "        \n",
    "        all_img_embeds.append(img_embeds.cpu()) # Move to CPU to save GPU memory\n",
    "        all_txt_embeds.append(txt_embeds.cpu())\n",
    "\n",
    "# Concatenate all batch embeddings into single tensors\n",
    "all_img_embeds = torch.cat(all_img_embeds).to(DEVICE) # Move back to GPU for similarity calc\n",
    "all_txt_embeds = torch.cat(all_txt_embeds).to(DEVICE)\n",
    "\n",
    "print(f\"\\nFinished calculating embeddings.\")\n",
    "print(f\"Image embeds shape: {all_img_embeds.shape}\") # Should be [5200, 512]\n",
    "print(f\"Text embeds shape:  {all_txt_embeds.shape}\") # Should be [5200, 512]\n",
    "\n",
    "# 3. Calculate Retrieval Accuracy (Recall@k)\n",
    "print(\"\\nCalculating retrieval accuracy...\")\n",
    "# Calculate the similarity matrix (cosine similarity)\n",
    "# Since embeddings are normalized, matmul is equivalent to cosine similarity\n",
    "similarity_matrix = all_img_embeds @ all_txt_embeds.T\n",
    "\n",
    "# Helper function to calculate Recall@k\n",
    "def calculate_recall(sim_matrix, k_values=(1, 5, 10)):\n",
    "    \"\"\"Calculates Recall@k for multiple k values.\"\"\"\n",
    "    n = len(sim_matrix)\n",
    "    targets = torch.arange(n).to(sim_matrix.device)\n",
    "    \n",
    "    # Get the indices of the top-k most similar text embeddings for each image\n",
    "    _, topk_indices = sim_matrix.topk(max(k_values), dim=1)\n",
    "    \n",
    "    recalls = {}\n",
    "    for k in k_values:\n",
    "        # Check if the correct target index is within the top-k predictions\n",
    "        correct_at_k = topk_indices[:, :k].eq(targets.view(-1, 1)).any(dim=1)\n",
    "        recalls[k] = (correct_at_k.sum() / n).item()\n",
    "    return recalls\n",
    "\n",
    "# Calculate and print recalls\n",
    "recall_results = calculate_recall(similarity_matrix, k_values=(1, 5, 10))\n",
    "\n",
    "print(f\"\\n--- CLIP Baseline Results (Image-to-Text Retrieval on Validation Set) ---\")\n",
    "for k, recall in recall_results.items():\n",
    "      print(f\"Recall@{k:<2}: {recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459d4bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/jet/home/pbhuyan/wandb/run-20251026_165447-eeg_retrieval_modelfc_run_1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval/runs/eeg_retrieval_modelfc_run_1' target=\"_blank\">eeg_retrieval_modelfc_run_1</a></strong> to <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval/runs/eeg_retrieval_modelfc_run_1' target=\"_blank\">https://wandb.ai/pbhuyan-carnegie-mellon-university/eeg-caption-retrieval/runs/eeg_retrieval_modelfc_run_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming retrieval run eeg_retrieval_modelfc_run_1...\n",
      "No retrieval checkpoint file found.\n",
      "--- Starting EEG-Caption Retrieval Training from Epoch 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2299c55302d64540a5e24bb64b937096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieval Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc4630b89fd498f91e11f43af9f3999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 001 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43abb42b0cf44a32bc560d52da304ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 001 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a7e5ded0544410a08404d3adf6005e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 002 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9db9b8886f49b1a64d4ea5dd4bd771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 002 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d767e072790b4d75913846cab1e4d75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 003 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f90156ecb84b09a4f978c1d66a5063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 003 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75a5959c3d84f7093b07eeda7b75368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 004 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33c73d6a18f4a209c03230c77189f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 004 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdada1ef8444df8a9cd66fc43005973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 005 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4c2852799746a0ab40282c026851d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 005 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512a825ffac948ee8162c72ce89e9ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 006 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce85363576a4f1b8d41f995cdd63150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 006 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c45f7225d2a4b9aab3657c01585d87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 007 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a454075106d34149b29b8c4852d41bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 007 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292eddda9d0f4f9997afc1a4cf097915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 008 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196afd10ea434951838cf2e279cfc198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 008 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb952931f5449ed8dbce607f686d707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 009 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c502b145647045d3b54a58513fcc8c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 009 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935bf2187c614d9f87939027d9018267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 010 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df2ff22547342c8a91a41b473c8d389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 010 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647b06e4a4224cec9e4752baf803a2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 011 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6ea865a2a041cd83e38f403ca11488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 011 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfed751c4a34a4eb8e251326336faf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 012 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f0e5305f7945e98641fe6e101cc4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 012 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6453be4efa684e588913b7f8344388b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 013 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d213b3f70a0c4814b9b7c09d124696e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 013 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e7bf7905564f74ab6d021070f9143b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 014 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2487f1927358436ba32884243f3767bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 014 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4007f2f1ce144208021cde1725c6c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 015 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a1e9bbcb96442e8aabb63ea85e43fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 015 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f4edf8761d4214944d1a8d38d79e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 016 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f045c6c9bd42c2a955713a2a18c2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 016 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f957114f524b43f6a46e974158a9c2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 017 Training:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dc654cf8d1478b99c0430e1a65f94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 017 Validation:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 200\u001b[39m\n\u001b[32m    197\u001b[39m val_bar = tqdm(val_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Validation\u001b[39m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43meeg_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaption_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43meeg_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43meeg_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 1. Get EEG embeddings\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eeg-env/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eeg-env/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eeg-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eeg-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1470\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1468\u001b[39m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[32m   1469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent_workers:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1473\u001b[39m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[32m   1474\u001b[39m \n\u001b[32m   1475\u001b[39m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eeg-env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1618\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1613\u001b[39m         \u001b[38;5;28mself\u001b[39m._mark_worker_as_unavailable(worker_id, shutdown=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1614\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._workers:\n\u001b[32m   1615\u001b[39m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[32m   1616\u001b[39m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1618\u001b[39m     \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._index_queues:\n\u001b[32m   1620\u001b[39m     q.cancel_join_thread()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/packages/anaconda3-2024.10-1/lib/python3.12/multiprocessing/process.py:149\u001b[39m, in \u001b[36mBaseProcess.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parent_pid == os.getpid(), \u001b[33m'\u001b[39m\u001b[33mcan only join a child process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mcan only join a started process\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_popen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    151\u001b[39m     _children.discard(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/packages/anaconda3-2024.10-1/lib/python3.12/multiprocessing/popen_fork.py:40\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmultiprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/packages/anaconda3-2024.10-1/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/packages/anaconda3-2024.10-1/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "from transformers import CLIPProcessor, CLIPModel # We need CLIP again\n",
    "\n",
    "# --- Define the EEG-Caption Model ---\n",
    "class EEGCaptionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines an EEG backbone (like ModelFC or ModelConv)\n",
    "    with a projection head to map EEG features into CLIP's space (512 dims).\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_backbone, output_dim=512):\n",
    "        super().__init__()\n",
    "        self.backbone = eeg_backbone\n",
    "        \n",
    "        # --- Determine backbone output size ---\n",
    "        # Get the output dimension from the backbone's final layer\n",
    "        # Assumes the backbone ends with a nn.Linear layer\n",
    "        if isinstance(eeg_backbone, ModelFC):\n",
    "            # ModelFC's last layer is nn.Linear(hid_dim, out_dim)\n",
    "            backbone_out_dim = eeg_backbone.model[-1].in_features \n",
    "        elif isinstance(eeg_backbone, ModelConv):\n",
    "             # ModelConv's last layer is nn.Linear(fc_in_dim, class_num)\n",
    "            backbone_out_dim = eeg_backbone.model_fc[0].in_features\n",
    "        # Add checks for ModelLSTM, ModelTransformer if you use them\n",
    "        else:\n",
    "            raise TypeError(\"Unsupported backbone type. Add logic to get output dim.\")\n",
    "        # ------------------------------------\n",
    "\n",
    "        # Projection head maps backbone output to CLIP's dimension\n",
    "        self.projection_head = nn.Linear(backbone_out_dim, output_dim)\n",
    "        \n",
    "    def forward(self, eeg):\n",
    "        # Pass EEG through the backbone\n",
    "        # Need to handle different backbone types if their forward needs adjustment\n",
    "        if isinstance(self.backbone, ModelFC):\n",
    "            # ModelFC expects [B, T, C] and flattens it\n",
    "             # Need to get features *before* the final classification layer\n",
    "            features = self.backbone.model[:-1](eeg.reshape(eeg.shape[0], -1)) # Get output of ReLU\n",
    "        elif isinstance(self.backbone, ModelConv):\n",
    "            # ModelConv expects [B, C, T] - Needs adjustment based on YOUR data!\n",
    "            # Your dataloader gives [B, T, C] -> [32, 500, 122]\n",
    "            x_transpose = eeg.transpose(dim0=1, dim1=2) # -> [32, 122, 500]\n",
    "            conv_out = self.backbone.model_conv(x_transpose)\n",
    "            bs = conv_out.shape[0]\n",
    "            features = conv_out.reshape([bs,-1]) # Features before final Linear\n",
    "            # Pass features through the linear layer of the Conv model's fc part, but NOT softmax\n",
    "            features = self.backbone.model_fc[0](features) # Output of the Linear layer\n",
    "\n",
    "        else:\n",
    "             raise TypeError(\"Unsupported backbone type for feature extraction.\")\n",
    "\n",
    "        # Pass features through the projection head\n",
    "        eeg_embeds = self.projection_head(features) # [B, 512]\n",
    "        return eeg_embeds\n",
    "\n",
    "# --- Contrastive Loss Function ---\n",
    "def contrastive_loss(eeg_embeds, txt_embeds, temperature=0.07):\n",
    "    # Normalize embeddings (important for cosine similarity)\n",
    "    eeg_embeds = eeg_embeds / eeg_embeds.norm(dim=-1, keepdim=True)\n",
    "    txt_embeds = txt_embeds / txt_embeds.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    # Calculate cosine similarity matrix (logit scale)\n",
    "    # Higher temperature -> softer probabilities, lower -> harder\n",
    "    logit_scale = clip_model.logit_scale.exp() # Use CLIP's learned scale\n",
    "    sim_matrix = (eeg_embeds @ txt_embeds.T) * logit_scale\n",
    "    \n",
    "    # Ground truth: diagonal elements are the correct pairs\n",
    "    labels = torch.arange(len(sim_matrix)).to(sim_matrix.device)\n",
    "    \n",
    "    # Calculate CrossEntropyLoss in both directions\n",
    "    loss_eeg_to_txt = nn.CrossEntropyLoss()(sim_matrix, labels)\n",
    "    loss_txt_to_eeg = nn.CrossEntropyLoss()(sim_matrix.T, labels)\n",
    "    \n",
    "    # Average the two losses\n",
    "    return (loss_eeg_to_txt + loss_txt_to_eeg) / 2.0\n",
    "\n",
    "# --- Helper function for Recall@k (same as before) ---\n",
    "def calculate_recall(sim_matrix, k_values=(1, 5, 10)):\n",
    "    n = len(sim_matrix)\n",
    "    targets = torch.arange(n).to(sim_matrix.device)\n",
    "    _, topk_indices = sim_matrix.topk(max(k_values), dim=1)\n",
    "    recalls = {}\n",
    "    for k in k_values:\n",
    "        correct_at_k = topk_indices[:, :k].eq(targets.view(-1, 1)).any(dim=1)\n",
    "        recalls[k] = (correct_at_k.sum() / n).item()\n",
    "    return recalls\n",
    "\n",
    "\n",
    "# --- Task 2c: Training Loop ---\n",
    "\n",
    "# --- 1. Define Run Configuration ---\n",
    "config_retrieval = {\n",
    "    \"model_name\": \"EEG_Caption_Retrieval_ModelFC\",\n",
    "    \"epochs\": 50, # Retrieval might need fewer/more epochs than classification\n",
    "    \"lr\": 1e-4, # May need tuning\n",
    "    \"batch_size\": 32, # From your dataloader\n",
    "    \"backbone\": \"ModelFC\", # Specify which backbone you're using\n",
    "    \"clip_model_name\": \"openai/clip-vit-base-patch32\",\n",
    "    \"contrastive_temperature\": 0.07, # Common default for CLIP\n",
    "}\n",
    "\n",
    "RUN_ID_RETRIEVAL = \"eeg_retrieval_modelfc_run_1\"\n",
    "CKPT_PATH_RETRIEVAL = f\"./{RUN_ID_RETRIEVAL}.pth\"\n",
    "\n",
    "# --- 2. Initialize W&B ---\n",
    "run_retrieval = wandb.init(\n",
    "    project=\"eeg-caption-retrieval\", # New project name\n",
    "    entity=\"pbhuyan-carnegie-mellon-university\", # *** YOUR W&B ENTITY ***\n",
    "    job_type=\"train\",\n",
    "    config=config_retrieval,\n",
    "    id=RUN_ID_RETRIEVAL,\n",
    "    resume=\"allow\",\n",
    ")\n",
    "\n",
    "# --- 3. Instantiate Models ---\n",
    "#    a) Load your trained EEG classification backbone (e.g., ModelFC)\n",
    "#       OR instantiate a new one if you want to train from scratch.\n",
    "#       Let's assume you want to use the already trained 'model_fc'\n",
    "eeg_backbone = model_fc # Using the model trained in the previous cell\n",
    "\n",
    "#    b) Create the full EEG-Caption model\n",
    "eeg_retrieval_model = EEGCaptionModel(eeg_backbone).to(DEVICE)\n",
    "\n",
    "#    c) Load the FROZEN CLIP model (for text embeddings and logit scale)\n",
    "#       (We already loaded 'clip_model' and 'clip_processor' in the previous cell)\n",
    "clip_model.eval()\n",
    "for param in clip_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --- 4. Define Optimizer ---\n",
    "# IMPORTANT: Only optimize the parameters of the EEG retrieval model\n",
    "optimizer = optim.Adam(eeg_retrieval_model.parameters(), lr=config_retrieval[\"lr\"])\n",
    "\n",
    "# --- 5. Load Checkpoint if Resuming ---\n",
    "start_epoch_retrieval = 0\n",
    "if wandb.run.resumed:\n",
    "    print(f\"Resuming retrieval run {RUN_ID_RETRIEVAL}...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(CKPT_PATH_RETRIEVAL)\n",
    "        eeg_retrieval_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch_retrieval = checkpoint['epoch'] + 1\n",
    "        print(f\"Resumed successfully. Starting from epoch {start_epoch_retrieval}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No retrieval checkpoint file found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading retrieval checkpoint: {e}.\")\n",
    "\n",
    "wandb.watch(eeg_retrieval_model, contrastive_loss, log=\"all\", log_freq=100)\n",
    "\n",
    "# --- 6. Retrieval Training Loop ---\n",
    "print(f\"--- Starting EEG-Caption Retrieval Training from Epoch {start_epoch_retrieval+1} ---\")\n",
    "epoch_bar_retrieval = tqdm(range(start_epoch_retrieval, config_retrieval[\"epochs\"]), desc=\"Retrieval Epochs\")\n",
    "\n",
    "for epoch in epoch_bar_retrieval:\n",
    "    \n",
    "    # --- Training Phase ---\n",
    "    eeg_retrieval_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1:03} Training\", leave=False)\n",
    "    \n",
    "    for eeg_batch, _, caption_batch, _ in train_bar: \n",
    "        eeg_batch = eeg_batch.to(DEVICE)\n",
    "        \n",
    "        # 1. Get EEG embeddings from your trainable model\n",
    "        eeg_embeds = eeg_retrieval_model(eeg_batch)\n",
    "        \n",
    "        # 2. Get Text embeddings from the FROZEN CLIP model\n",
    "        with torch.no_grad():\n",
    "            text_inputs = clip_processor(\n",
    "                text=list(caption_batch), return_tensors=\"pt\", padding=True, truncation=True\n",
    "            ).to(DEVICE)\n",
    "            txt_embeds = clip_model.get_text_features(**text_inputs)\n",
    "        \n",
    "        # 3. Calculate Contrastive Loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = contrastive_loss(eeg_embeds, txt_embeds, temperature=config_retrieval[\"contrastive_temperature\"])\n",
    "        \n",
    "        # 4. Backpropagate and update weights (only affects EEG model)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    eeg_retrieval_model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_eeg_embeds = []\n",
    "    all_txt_embeds = []\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1:03} Validation\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg_batch, _, caption_batch, _ in val_bar:\n",
    "            eeg_batch = eeg_batch.to(DEVICE)\n",
    "            \n",
    "            # 1. Get EEG embeddings\n",
    "            eeg_embeds = eeg_retrieval_model(eeg_batch)\n",
    "            \n",
    "            # 2. Get Text embeddings\n",
    "            text_inputs = clip_processor(\n",
    "                text=list(caption_batch), return_tensors=\"pt\", padding=True, truncation=True\n",
    "            ).to(DEVICE)\n",
    "            txt_embeds = clip_model.get_text_features(**text_inputs)\n",
    "\n",
    "            # Calculate loss (optional, but good for monitoring)\n",
    "            loss = contrastive_loss(eeg_embeds, txt_embeds, temperature=config_retrieval[\"contrastive_temperature\"])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Normalize embeddings for recall calculation\n",
    "            eeg_embeds /= eeg_embeds.norm(dim=-1, keepdim=True)\n",
    "            txt_embeds /= txt_embeds.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            all_eeg_embeds.append(eeg_embeds.cpu())\n",
    "            all_txt_embeds.append(txt_embeds.cpu())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate Recall@k on validation set\n",
    "    all_eeg_embeds = torch.cat(all_eeg_embeds).to(DEVICE)\n",
    "    all_txt_embeds = torch.cat(all_txt_embeds).to(DEVICE)\n",
    "    val_sim_matrix = all_eeg_embeds @ all_txt_embeds.T\n",
    "    recall_results = calculate_recall(val_sim_matrix, k_values=(1, 5))\n",
    "    \n",
    "    # --- 7. Log Metrics to W&B ---\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": avg_train_loss,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_recall_at_1\": recall_results[1],\n",
    "        \"val_recall_at_5\": recall_results[5],\n",
    "    })\n",
    "    \n",
    "    # Update the main epoch bar\n",
    "    epoch_bar_retrieval.set_postfix(\n",
    "        Train_Loss=f\"{avg_train_loss:.4f}\", \n",
    "        Val_Loss=f\"{avg_val_loss:.4f}\", \n",
    "        Val_R_at_1=f\"{recall_results[1]*100:.2f}%\",\n",
    "        Val_R_at_5=f\"{recall_results[5]*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # --- 8. Save Checkpoint ---\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': eeg_retrieval_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_val_loss, # Save validation loss\n",
    "    }, CKPT_PATH_RETRIEVAL)\n",
    "\n",
    "# --- 9. Finish the W&B Run ---\n",
    "wandb.finish()\n",
    "print(f\"--- {config_retrieval['model_name']} training complete. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eeg-venv)",
   "language": "python",
   "name": "eeg-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
