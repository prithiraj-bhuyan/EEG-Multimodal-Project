{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG-Based Visual Recognition: Classification to Semantic Retrieval\n",
    "## Final Project Submission - Group 10\n",
    "\n",
    "**Team Members:** Madhavi Gulavani, Praneeth Chaitanya Jonnavithula, Prithiraj Bhuyan\n",
    "\n",
    "**Course:** 11-685 Introduction to Deep Learning (Fall 2025)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook implements:\n",
    "1. **Task 1**: EEG-based image classification with advanced architectures\n",
    "2. **Task 2A**: Image-Caption retrieval using pretrained CLIP\n",
    "3. **Task 2B**: EEG-Caption retrieval with various CLIP fine-tuning strategies\n",
    "4. **Comprehensive Evaluation**: All required metrics and analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set Seed\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /jet/home/gulavani/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to WandB\n",
    "wandb.login(key=\"825201e63a02e53435b53a136158ab39815c89a4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIDS_ROOT = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/ds005589'\n",
    "IMAGE_DIR = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/images'\n",
    "CAPTIONS_FILE = '/ocean/projects/cis250019p/gandotra/11785-gp-eeg/captions.txt'\n",
    "ALL_SUBJECTS = ['sub-02', 'sub-03', 'sub-05', 'sub-09', 'sub-14', 'sub-15', \n",
    "                'sub-17', 'sub-19', 'sub-20', 'sub-23', 'sub-24', 'sub-28', 'sub-29']\n",
    "\n",
    "class EEG_Paper_Replication_Dataset(Dataset):\n",
    "    def __init__(self, bids_root, images_dir, captions_path, \n",
    "                 subject_list, session_list, \n",
    "                 clamp_thres=500, stats=None):\n",
    "        \n",
    "        self.bids_root = bids_root\n",
    "        self.images_dir = images_dir\n",
    "        self.clamp_thres = clamp_thres\n",
    "        self.trial_metadata = []\n",
    "        \n",
    "        # --- Create Subject Mapping ---\n",
    "        # Map 'sub-02' -> 0, 'sub-03' -> 1, etc.\n",
    "        # We sort to ensure consistency across Train/Val/Test sets\n",
    "        self.subject_to_idx = {sub: i for i, sub in enumerate(sorted(list(set(subject_list))))}\n",
    "        \n",
    "        # 1. Load Captions Helper\n",
    "        self.captions_dict = self._load_captions(captions_path)\n",
    "        self.category_to_idx = {cat: i for i, cat in enumerate(sorted(set(c for c, _ in self.captions_dict.values())))}\n",
    "        \n",
    "        # 2. Scan Metadata\n",
    "        print(f\"Scanning metadata for {session_list}...\")\n",
    "        for sub in subject_list:\n",
    "            for ses in session_list:\n",
    "                for run in ['01', '02', '03', '04']:\n",
    "                    session_path = os.path.join(self.bids_root, sub, ses)\n",
    "                    csv_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_image.csv\")\n",
    "                    npy_path = os.path.join(session_path, f\"{sub}_{ses}_task-lowSpeed_run-{run}_1000Hz.npy\")\n",
    "                    \n",
    "                    if not (os.path.exists(csv_path) and os.path.exists(npy_path)):\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        csv_data = pd.read_csv(csv_path)\n",
    "                        for i, row in csv_data.iterrows():\n",
    "                            img_base_name = self._get_base_name(row['FilePath'])\n",
    "                            if not img_base_name: continue\n",
    "                            \n",
    "                            category, caption = self.captions_dict.get(img_base_name, (None, None))\n",
    "                            if not category: continue\n",
    "                            \n",
    "                            self.trial_metadata.append({\n",
    "                                'npy_path': npy_path,\n",
    "                                'trial_index': i,\n",
    "                                'label': self.category_to_idx[category],\n",
    "                                'subject_id': self.subject_to_idx[sub],\n",
    "                                'image_name': img_base_name,\n",
    "                                'caption': caption \n",
    "                            })\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"Found {len(self.trial_metadata)} trials.\")\n",
    "\n",
    "        # 3. Compute Global Statistics (GFS)\n",
    "        if stats is None:\n",
    "            print(\"Computing Global Statistics (this takes ~1 min)...\")\n",
    "            self.mean, self.std = self._compute_global_stats()\n",
    "        else:\n",
    "            self.mean, self.std = stats\n",
    "\n",
    "    def _compute_global_stats(self):\n",
    "        subset_indices = range(0, len(self.trial_metadata), 10)\n",
    "        sum_x = 0\n",
    "        sum_sq_x = 0\n",
    "        count = 0\n",
    "        \n",
    "        for i in tqdm(subset_indices, desc=\"Calculating Stats\"):\n",
    "            meta = self.trial_metadata[i]\n",
    "            d = np.load(meta['npy_path'])[meta['trial_index']]\n",
    "            d = np.clip(d, -self.clamp_thres, self.clamp_thres)\n",
    "            \n",
    "            sum_x += np.mean(d)\n",
    "            sum_sq_x += np.mean(d**2)\n",
    "            count += 1\n",
    "            \n",
    "        global_mean = sum_x / count\n",
    "        global_std = np.sqrt((sum_sq_x / count) - (global_mean**2))\n",
    "        return float(global_mean), float(global_std)\n",
    "\n",
    "    def get_stats(self): return self.mean, self.std\n",
    "\n",
    "    def _load_captions(self, path):\n",
    "        d = {}\n",
    "        with open(path, 'r') as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 4: d[parts[2]] = (parts[1], parts[3])\n",
    "        return d\n",
    "\n",
    "    def _get_base_name(self, p):\n",
    "        try:\n",
    "            bn = os.path.splitext(os.path.basename(str(p).replace('\\\\', '/')))[0]\n",
    "            if bn.endswith('_resized'): return bn[:-8]\n",
    "            return bn\n",
    "        except: return None\n",
    "\n",
    "    def _get_image_path(self, image_name):\n",
    "        \"\"\"Find full path to image file\"\"\"\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPEG', '.JPG']:\n",
    "            path = os.path.join(self.images_dir, image_name + ext)\n",
    "            if os.path.exists(path):\n",
    "                return path\n",
    "        return None  # Image not found\n",
    "\n",
    "    def __len__(self): return len(self.trial_metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        meta = self.trial_metadata[idx]\n",
    "        eeg_data = np.load(meta['npy_path'])[meta['trial_index']]\n",
    "        eeg_data = np.clip(eeg_data, -self.clamp_thres, self.clamp_thres)\n",
    "        # Global Feature Standardization\n",
    "        eeg_data = (eeg_data - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        img_path = self._get_image_path(meta['image_name'])\n",
    "        caption = meta['caption']\n",
    "        \n",
    "        return {\n",
    "            'eeg': torch.tensor(eeg_data, dtype=torch.float32),\n",
    "            'label': torch.tensor(meta['label'], dtype=torch.long),\n",
    "            'subject_id': torch.tensor(meta['subject_id'], dtype=torch.long),\n",
    "            'image_path': img_path,  # for Task 2\n",
    "            'caption': caption  # for Task 2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Init Train ---\n",
      "Scanning metadata for ['ses-01', 'ses-02', 'ses-03']...\n",
      "Found 15600 trials.\n",
      "Computing Global Statistics (this takes ~1 min)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3f4e85342c4f22a8267aa66dbfd4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Stats:   0%|          | 0/1560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Init Validation ---\n",
      "Scanning metadata for ['ses-04']...\n",
      "Found 5200 trials.\n",
      "Loading Test Set (Session 5)...\n",
      "Scanning metadata for ['ses-05']...\n",
      "Found 5200 trials.\n",
      "\n",
      "‚úÖ Loaders Ready: 488 training batches, 163 validation batches.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE DATASETS AND DATALOADERS\n",
    "# ============================================================================\n",
    "# 1. Create Transforms (Standard ImageNet stats)\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Instantiate Training Dataset\n",
    "print(\"--- Init Train ---\")\n",
    "train_ds = EEG_Paper_Replication_Dataset(\n",
    "    bids_root=BIDS_ROOT, \n",
    "    images_dir=IMAGE_DIR, \n",
    "    captions_path=CAPTIONS_FILE, \n",
    "    subject_list=ALL_SUBJECTS, \n",
    "    session_list=['ses-01', 'ses-02', 'ses-03'], \n",
    "    clamp_thres=500\n",
    ")\n",
    "# Save stats to use for validation (Prevent data leakage)\n",
    "stats = train_ds.get_stats()\n",
    "\n",
    "# 3. Instantiate Validation Dataset\n",
    "print(\"\\n--- Init Validation ---\")\n",
    "val_ds = EEG_Paper_Replication_Dataset(\n",
    "    bids_root=BIDS_ROOT, \n",
    "    images_dir=IMAGE_DIR, \n",
    "    captions_path=CAPTIONS_FILE, \n",
    "    subject_list=ALL_SUBJECTS, \n",
    "    session_list=['ses-04'], \n",
    "    clamp_thres=500,\n",
    "    stats=stats # <--- IMPORTANT: Use training stats\n",
    ")\n",
    "\n",
    "print(\"Loading Test Set (Session 5)...\")\n",
    "test_ds = EEG_Paper_Replication_Dataset(\n",
    "    BIDS_ROOT, IMAGE_DIR, CAPTIONS_FILE, ALL_SUBJECTS, \n",
    "    ['ses-05'], # FINAL TEST SET\n",
    "    stats=stats,\n",
    "    clamp_thres=500\n",
    ")\n",
    "\n",
    "# 4. Define The Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"\\n‚úÖ Loaders Ready: {len(train_loader)} training batches, {len(val_loader)} validation batches.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: EEG Classification\n",
    "\n",
    "### Model Architecture\n",
    "\n",
    "We implement a multi-head architecture with:\n",
    "1. **CNN Feature Extractor**: Extracts temporal features from EEG channels\n",
    "2. **Transformer Backbone**: Models relationships across channels (shared across subjects)\n",
    "3. **Subject-Specific Heads**: Separate classification heads for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ViT_1D(nn.Module):\n",
    "    def __init__(self, num_subjects=13, num_classes=20):\n",
    "        super().__init__()\n",
    "        \n",
    "        # --- Hyperparameters ---\n",
    "        self.patch_size = 50      # 50ms window \n",
    "        self.stride = 25          # 50% overlap\n",
    "        self.embed_dim = 128      # Feature size\n",
    "        self.num_heads = 4\n",
    "        self.depth = 2\n",
    "        \n",
    "        # --- 1. Tokenizer (The \"Patchify\" Step) ---\n",
    "        # Input: (Batch, 122, 500) -> Output: (Batch, 128, ~19)\n",
    "        self.tokenizer = nn.Sequential(\n",
    "            nn.Conv1d(122, self.embed_dim, kernel_size=self.patch_size, stride=self.stride, padding=0),\n",
    "            nn.BatchNorm1d(self.embed_dim),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        \n",
    "        # --- 2. Learnable \"Class Token\" ---\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, self.embed_dim))\n",
    "        \n",
    "        # --- 3. Positional Embedding ---\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 32, self.embed_dim) * 0.01)\n",
    "        \n",
    "        # --- 4. Transformer Encoder ---\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dim, \n",
    "            nhead=self.num_heads, \n",
    "            dim_feedforward=512, \n",
    "            dropout=0.5, \n",
    "            batch_first=True,\n",
    "            norm_first=True \n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=self.depth)\n",
    "        \n",
    "        # --- 5. Subject-Specific Heads ---\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(self.embed_dim, num_classes) for _ in range(num_subjects)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, subject_ids):\n",
    "        # Input comes in as (Batch, 500, 122) -> We need (Batch, 122, 500)\n",
    "        if x.shape[1] == 500 and x.shape[2] == 122:\n",
    "            x = x.permute(0, 2, 1)\n",
    "            \n",
    "        # Safety Crop (in case data is >500)\n",
    "        if x.shape[2] > 500:\n",
    "            x = x[:, :, :500]\n",
    "            \n",
    "        # ----------------------------------------\n",
    "        \n",
    "        # 1. Tokenize\n",
    "        x = self.tokenizer(x)     # Output: (Batch, 128, 19)\n",
    "        x = x.permute(0, 2, 1)    # Output: (Batch, 19, 128) -> (Batch, Seq, Dim)\n",
    "        \n",
    "        b, seq_len, _ = x.shape\n",
    "        \n",
    "        # 2. Append CLS Token\n",
    "        cls_tokens = self.cls_token.expand(b, -1, -1) \n",
    "        x = torch.cat((cls_tokens, x), dim=1) # (Batch, 20, 128)\n",
    "        \n",
    "        # 3. Add Positional Embedding\n",
    "        x = x + self.pos_embedding[:, :seq_len + 1, :]\n",
    "        \n",
    "        # 4. Transformer Attention\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 5. Extract ONLY the CLS token output\n",
    "        cls_output = x[:, 0, :]   # (Batch, 128)\n",
    "        \n",
    "        # 6. Subject Routing\n",
    "        logits = torch.zeros(x.shape[0], 20).to(x.device)\n",
    "        unique_subs = torch.unique(subject_ids)\n",
    "        \n",
    "        for sub in unique_subs:\n",
    "            mask = (subject_ids == sub)\n",
    "            logits[mask] = self.heads[sub.long()](cls_output[mask])\n",
    "            \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_TRAINING = False\n",
    "CHECKPOINT_PATH = \"best_model_vit_1d.pth\"\n",
    "TOTAL_EPOCHS = 100\n",
    "\n",
    "wandb.init(\n",
    "    project=\"eeg-classification\",\n",
    "    name=\"vit-1d-run\",\n",
    "    config={\n",
    "        \"architecture\": \"ViT-1D\",\n",
    "        \"dataset\": \"GFS\",\n",
    "        \"epochs\": TOTAL_EPOCHS,\n",
    "        \"lr\": 1e-3\n",
    "    }\n",
    ")\n",
    "\n",
    "model = EEG_ViT_1D(num_subjects=13, num_classes=20).to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "start_epoch = 1\n",
    "best_val_acc = 0.0\n",
    "\n",
    "if RESUME_TRAINING and os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"üîÑ Attempting to resume from {CHECKPOINT_PATH}...\")\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "        \n",
    "        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            start_epoch = checkpoint.get('epoch', 0) + 1\n",
    "            best_val_acc = checkpoint.get('val_acc', 0.0)\n",
    "            print(f\"‚úÖ Resuming from Epoch {start_epoch} with Best Acc {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"‚ö†Ô∏è Only weights found. Resuming from Epoch 1.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading checkpoint: {e}. Starting fresh.\")\n",
    "else:\n",
    "    print(\"üÜï Starting a fresh training run.\")\n",
    "\n",
    "print(f\"\\nüöÄ Training from Epoch {start_epoch} to {TOTAL_EPOCHS}...\")\n",
    "\n",
    "for epoch in range(start_epoch, TOTAL_EPOCHS + 1):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        eeg = batch['eeg'].to(DEVICE)\n",
    "        label = batch['label'].to(DEVICE)\n",
    "        sub_id = batch['subject_id'].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(eeg, sub_id)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred = outputs.max(1)\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        total += label.size(0)\n",
    "        \n",
    "    train_acc = 100. * correct / total\n",
    "    \n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            eeg = batch['eeg'].to(DEVICE)\n",
    "            label = batch['label'].to(DEVICE)\n",
    "            sub_id = batch['subject_id'].to(DEVICE)\n",
    "            \n",
    "            outputs = model(eeg, sub_id)\n",
    "            _, pred = outputs.max(1)\n",
    "            val_correct += pred.eq(label).sum().item()\n",
    "            val_total += label.size(0)\n",
    "            \n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch {epoch:02d}: Train Acc {train_acc:.2f}% | Val Acc {val_acc:.2f}%\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"train_loss\": loss.item()\n",
    "    })\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'train_acc': train_acc\n",
    "        }, CHECKPOINT_PATH)\n",
    "        \n",
    "        wandb.save(CHECKPOINT_PATH) \n",
    "        \n",
    "        print(f\"  ‚úÖ Best Model Saved & Uploaded! ({val_acc:.2f}%)\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_detailed(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    subject_results = {i: {'correct': 0, 'total': 0} for i in range(len(ALL_SUBJECTS))}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for eeg, label, sub_id in tqdm(loader, desc=\"Testing\"):\n",
    "            eeg, label, sub_id = eeg.to(device), label.to(device), sub_id.to(device)\n",
    "            \n",
    "            outputs = model(eeg, sub_id)\n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "            for i in range(len(label)):\n",
    "                sid = sub_id[i].item()\n",
    "                is_correct = (preds[i] == label[i]).item()\n",
    "                subject_results[sid]['total'] += 1\n",
    "                subject_results[sid]['correct'] += is_correct\n",
    "                \n",
    "    return all_labels, all_preds, subject_results\n",
    "\n",
    "print(\"Running Final Evaluation...\")\n",
    "y_true, y_pred, sub_metrics = evaluate_detailed(model, test_loader, DEVICE)\n",
    "\n",
    "overall_acc = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"\\nüèÜ Final Test Accuracy: {overall_acc:.2f}%\")\n",
    "\n",
    "sub_accs = []\n",
    "sub_names = []\n",
    "for sid, metrics in sub_metrics.items():\n",
    "    if metrics['total'] > 0:\n",
    "        acc = (metrics['correct'] / metrics['total']) * 100\n",
    "        sub_accs.append(acc)\n",
    "        sub_names.append(ALL_SUBJECTS[sid])\n",
    "        \n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=sub_names, y=sub_accs, palette=\"viridis\")\n",
    "plt.axhline(y=overall_acc, color='r', linestyle='--', label=f'Avg: {overall_acc:.1f}%')\n",
    "plt.axhline(y=5.0, color='gray', linestyle='--', label='Random Chance (5%)')\n",
    "plt.title(\"Per-Subject Classification Accuracy (Session 5)\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cat_map = {v: k for k, v in test_ds.category_to_idx.items()}\n",
    "cat_names = [cat_map[i] for i in range(len(cat_map))]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm_norm, annot=False, fmt=\".2f\", cmap=\"Blues\", xticklabels=cat_names, yticklabels=cat_names)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MADHAVI'S CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL SELECTION HELPER FOR TASK 2B\n",
    "# ============================================================================\n",
    "\n",
    "def load_task1_encoder(model_type, task1_run_id, device):\n",
    "    \"\"\"\n",
    "    Load the trained encoder from Task 1 for use in Task 2B\n",
    "    \n",
    "    Args:\n",
    "        model_type: \"baseline\", \"cnn\", or \"multihead\"\n",
    "        task1_run_id: wandb run ID from Task 1 training\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        encoder: The trained encoder module\n",
    "        encoder_dim: Output dimension of encoder\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüì• Loading Task 1 encoder ({model_type})...\")\n",
    "    \n",
    "    # Download checkpoint from wandb\n",
    "    checkpoint_file = wandb.restore(\n",
    "        'best_model.pth', \n",
    "        run_path=f\"{wandb.run.entity}/eeg-visual-recognition/{task1_run_id}\"\n",
    "    )\n",
    "    checkpoint = torch.load(checkpoint_file.name, map_location=device)\n",
    "    \n",
    "    # Create the same model architecture\n",
    "    if model_type == \"baseline\":\n",
    "        model = BaselineEEGClassifier(\n",
    "            input_dim=122*500,\n",
    "            hidden_dim=512,\n",
    "            num_classes=20,\n",
    "            dropout=0.5\n",
    "        ).to(device)\n",
    "        encoder_dim = 256\n",
    "        \n",
    "    elif model_type == \"cnn\":\n",
    "        model = CNNEEGClassifier(\n",
    "            num_channels=122,\n",
    "            num_timepoints=500,\n",
    "            num_classes=20\n",
    "        ).to(device)\n",
    "        encoder_dim = 256\n",
    "        \n",
    "    elif model_type == \"multihead\":\n",
    "        model = MultiHeadEEGClassifier(\n",
    "            num_subjects=13,\n",
    "            num_classes=20,\n",
    "            backbone_dim=256\n",
    "        ).to(device)\n",
    "        encoder_dim = 256\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "    \n",
    "    # Load trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Extract encoder\n",
    "    encoder = model.get_encoder()\n",
    "    \n",
    "    print(f\"‚úì Loaded encoder from Task 1\")\n",
    "    print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"  Val Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    print(f\"  Encoder output dim: {encoder_dim}\")\n",
    "    \n",
    "    return encoder, encoder_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETED\n",
      "============================================================\n",
      "Best Validation Accuracy: 9.92%\n",
      "Chance Level: 5.00%\n",
      "Above Chance: ‚úì YES\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TRAINING COMPLETED\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Accuracy: {results['best_val_acc']:.2f}%\")\n",
    "print(f\"Chance Level: {100/20:.2f}%\")\n",
    "print(f\"Above Chance: {'‚úì YES' if results['best_val_acc'] > 5 else '‚úó NO'}\")\n",
    "\n",
    "# # Plot training curves\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# ax1.plot(results['history']['train_loss'])\n",
    "# ax1.set_title('Training Loss')\n",
    "# ax1.set_xlabel('Epoch')\n",
    "# ax1.set_ylabel('Loss')\n",
    "# ax1.grid(True)\n",
    "\n",
    "# ax2.plot(results['history']['train_acc'], label='Train')\n",
    "# ax2.plot(results['history']['val_acc'], label='Val')\n",
    "# ax2.axhline(y=5, color='r', linestyle='--', label='Chance')\n",
    "# ax2.set_title('Accuracy')\n",
    "# ax2.set_xlabel('Epoch')\n",
    "# ax2.set_ylabel('Accuracy (%)')\n",
    "# ax2.legend()\n",
    "# ax2.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'task1_{MODEL_TYPE}_training_curves.png', dpi=150)\n",
    "# print(f\"\\n‚úì Training curves saved to: task1_{MODEL_TYPE}_training_curves.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 1: EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_task1(model, test_loader, device, use_subject_heads=False):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation for Task 1\n",
    "    \n",
    "    Args:\n",
    "        model: Trained classifier\n",
    "        test_loader: Test data loader\n",
    "        device: torch device\n",
    "        use_subject_heads: Whether model uses subject-specific heads\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with all evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_subjects = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating Task 1\"):\n",
    "            eeg = batch['eeg'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            subject_ids = batch['subject_id'].to(device)\n",
    "            \n",
    "            if use_subject_heads:\n",
    "                outputs = model(eeg, subject_ids)\n",
    "            else:\n",
    "                outputs = model(eeg)\n",
    "            \n",
    "            _, preds = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_subjects.extend(subject_ids.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_subjects = np.array(all_subjects)\n",
    "    \n",
    "    # ========== OVERALL ACCURACY ==========\n",
    "    overall_acc = 100. * accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # ========== PER-SUBJECT ACCURACY ==========\n",
    "    subject_accs = {}\n",
    "    for sid in np.unique(all_subjects):\n",
    "        mask = all_subjects == sid\n",
    "        if mask.any():\n",
    "            subject_accs[sid] = 100. * accuracy_score(all_labels[mask], all_preds[mask])\n",
    "    \n",
    "    # ========== CONFUSION MATRIX ==========\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # ========== PER-CLASS ACCURACY ==========\n",
    "    class_accs = {}\n",
    "    for class_id in range(20):\n",
    "        mask = all_labels == class_id\n",
    "        if mask.any():\n",
    "            class_accs[class_id] = 100. * accuracy_score(all_labels[mask], all_preds[mask])\n",
    "    \n",
    "    # ========== PRINT RESULTS ==========\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TASK 1: CLASSIFICATION RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nüìä Overall Performance:\")\n",
    "    print(f\"   Test Accuracy: {overall_acc:.2f}%\")\n",
    "    print(f\"   Chance Level: {100/20:.2f}%\")\n",
    "    print(f\"   Above Chance: {'‚úì YES' if overall_acc > 5 else '‚úó NO'}\")\n",
    "    \n",
    "    print(f\"\\nüë• Per-Subject Accuracy:\")\n",
    "    for sid, acc in sorted(subject_accs.items()):\n",
    "        print(f\"   Subject {sid:2d}: {acc:5.2f}%\")\n",
    "    \n",
    "    avg_subject_acc = np.mean(list(subject_accs.values()))\n",
    "    std_subject_acc = np.std(list(subject_accs.values()))\n",
    "    print(f\"\\n   Mean ¬± Std: {avg_subject_acc:.2f}% ¬± {std_subject_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Per-Class Accuracy:\")\n",
    "    class_names = [\n",
    "        'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "        'bus', 'car', 'cat', 'chair', 'cow',\n",
    "        'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "        'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "    ]\n",
    "    \n",
    "    # Sort by accuracy\n",
    "    sorted_classes = sorted(class_accs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\n   Top 5 Classes:\")\n",
    "    for class_id, acc in sorted_classes[:5]:\n",
    "        print(f\"   {class_names[class_id]:15s}: {acc:5.2f}%\")\n",
    "    \n",
    "    print(\"\\n   Bottom 5 Classes:\")\n",
    "    for class_id, acc in sorted_classes[-5:]:\n",
    "        print(f\"   {class_names[class_id]:15s}: {acc:5.2f}%\")\n",
    "    \n",
    "    # ========== CONFUSION MATRIX VISUALIZATION ==========\n",
    "    print(f\"\\nüìà Confusion Matrix Summary:\")\n",
    "    print(f\"   Diagonal (correct): {np.diag(cm).sum()}\")\n",
    "    print(f\"   Off-diagonal (errors): {cm.sum() - np.diag(cm).sum()}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix (Accuracy: {overall_acc:.2f}%)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'viz/task1_confusion_matrix_{MODEL_TYPE}.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"\\n‚úì Confusion matrix saved to: viz/task1_confusion_matrix_{MODEL_TYPE}.png\")\n",
    "    \n",
    "    return {\n",
    "        'overall_acc': overall_acc,\n",
    "        'subject_accs': subject_accs,\n",
    "        'class_accs': class_accs,\n",
    "        'confusion_matrix': cm,\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'subjects': all_subjects\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING BEST MODEL FOR EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LOADING BEST MODEL\n",
      "============================================================\n",
      "‚úì Loaded model from epoch 21\n",
      "  Validation accuracy: 9.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Task 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163/163 [00:21<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK 1: CLASSIFICATION RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä Overall Performance:\n",
      "   Test Accuracy: 9.54%\n",
      "   Chance Level: 5.00%\n",
      "   Above Chance: ‚úì YES\n",
      "\n",
      "üë• Per-Subject Accuracy:\n",
      "   Subject  0:  6.75%\n",
      "   Subject  1:  7.25%\n",
      "   Subject  2: 11.25%\n",
      "   Subject  3: 11.25%\n",
      "   Subject  4:  8.50%\n",
      "   Subject  5:  7.25%\n",
      "   Subject  6: 11.00%\n",
      "   Subject  7:  7.00%\n",
      "   Subject  8:  9.25%\n",
      "   Subject  9: 14.00%\n",
      "   Subject 10:  9.25%\n",
      "   Subject 11: 11.50%\n",
      "   Subject 12:  9.75%\n",
      "\n",
      "   Mean ¬± Std: 9.54% ¬± 2.11%\n",
      "\n",
      "üìÅ Per-Class Accuracy:\n",
      "\n",
      "   Top 5 Classes:\n",
      "   pottedplant    : 20.38%\n",
      "   boat           : 19.23%\n",
      "   chair          : 17.31%\n",
      "   horse          : 15.38%\n",
      "   dog            : 13.85%\n",
      "\n",
      "   Bottom 5 Classes:\n",
      "   sheep          :  5.00%\n",
      "   cow            :  4.23%\n",
      "   motorbike      :  3.85%\n",
      "   bird           :  3.46%\n",
      "   person         :  2.69%\n",
      "\n",
      "üìà Confusion Matrix Summary:\n",
      "   Diagonal (correct): 496\n",
      "   Off-diagonal (errors): 4704\n",
      "\n",
      "‚úì Confusion matrix saved to: task1_confusion_matrix.png\n",
      "\n",
      "‚úì Results saved to: task1_baseline_results.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========== LOAD AND EVALUATE BEST MODEL ==========\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING BEST MODEL FOR EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load best model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checkpoint = torch.load(f'checkpoints/best_baseline_task1.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úì Loaded model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"  Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate_task1(model, test_loader, device)\n",
    "\n",
    "# Save results\n",
    "results_summary = {\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'overall_accuracy': float(results['overall_acc']),\n",
    "    'chance_level': 5.0,\n",
    "    'above_chance': results['overall_acc'] > 5,\n",
    "    'subject_accuracies': {int(k): float(v) for k, v in results['subject_accs'].items()},\n",
    "    'class_accuracies': {int(k): float(v) for k, v in results['class_accs'].items()}\n",
    "}\n",
    "\n",
    "with open(f'task1_{MODEL_TYPE}_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Results saved to: task1_{MODEL_TYPE}_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jet/home/gulavani\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2A: Image-Caption Retrieval with CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK 2A: IMAGE-CAPTION RETRIEVAL WITH CLIP\n",
      "============================================================\n",
      "‚úì CLIP model loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 2A: IMAGE-CAPTION RETRIEVAL WITH CLIP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load pretrained CLIP\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(DEVICE)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "clip_model.eval()\n",
    "for param in clip_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"‚úì CLIP model loaded\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_clip_embeddings(dataset, clip_model, clip_processor, clip_tokenizer, \n",
    "                            device, batch_size=32):\n",
    "    \"\"\"Extract CLIP embeddings for images and captions\"\"\"\n",
    "    \n",
    "    # Get unique images and captions\n",
    "    unique_data = {}\n",
    "    for item in dataset.trial_metadata:\n",
    "        img_name = item['image_name']  # Changed\n",
    "        if img_name not in unique_data:\n",
    "            img_path = dataset._get_image_path(img_name)\n",
    "            unique_data[img_name] = {\n",
    "                'caption': item['caption'],\n",
    "                'category_label': item['label'],  # Changed\n",
    "                'img_path': img_path\n",
    "            }\n",
    "    \n",
    "    image_names = list(unique_data.keys())\n",
    "    captions = [unique_data[name]['caption'] for name in image_names]\n",
    "    labels = torch.tensor([unique_data[name]['category_label'] for name in image_names])\n",
    "    \n",
    "    print(f\"Extracting embeddings for {len(image_names)} unique images...\")\n",
    "    \n",
    "    image_embeddings = []\n",
    "    text_embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(image_names), batch_size)):\n",
    "        batch_names = image_names[i:i+batch_size]\n",
    "        batch_captions = captions[i:i+batch_size]\n",
    "        \n",
    "        # Load images\n",
    "        batch_images = []\n",
    "        for name in batch_names:\n",
    "            try:\n",
    "                img = Image.open(unique_data[name]['img_path']).convert('RGB')\n",
    "                batch_images.append(img)\n",
    "            except:\n",
    "                batch_images.append(Image.new('RGB', (224, 224)))\n",
    "        \n",
    "        # Process\n",
    "        image_inputs = clip_processor(images=batch_images, return_tensors=\"pt\", padding=True)\n",
    "        image_inputs = {k: v.to(device) for k, v in image_inputs.items()}\n",
    "        \n",
    "        text_inputs = clip_tokenizer(batch_captions, padding=True, truncation=True, \n",
    "                                    return_tensors=\"pt\", max_length=77)\n",
    "        text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
    "        \n",
    "        # Get embeddings\n",
    "        image_features = clip_model.get_image_features(**image_inputs)\n",
    "        text_features = clip_model.get_text_features(**text_inputs)\n",
    "        \n",
    "        # Normalize\n",
    "        image_features = F.normalize(image_features, p=2, dim=-1)\n",
    "        text_features = F.normalize(text_features, p=2, dim=-1)\n",
    "        \n",
    "        image_embeddings.append(image_features.cpu())\n",
    "        text_embeddings.append(text_features.cpu())\n",
    "    \n",
    "    image_embeddings = torch.cat(image_embeddings, dim=0)\n",
    "    text_embeddings = torch.cat(text_embeddings, dim=0)\n",
    "    \n",
    "    return {\n",
    "        'image_names': image_names,\n",
    "        'captions': captions,\n",
    "        'labels': labels,\n",
    "        'image_embeddings': image_embeddings,\n",
    "        'text_embeddings': text_embeddings\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_recall_at_k(similarities, k_values=[1, 3, 5], class_aware=False, labels=None):\n",
    "    \"\"\"Compute Recall@K\"\"\"\n",
    "    N = similarities.shape[0]\n",
    "    \n",
    "    # Move similarities to same device for sorting\n",
    "    device = similarities.device\n",
    "    top_k_indices = torch.argsort(similarities, dim=1, descending=True)\n",
    "    \n",
    "    # Ensure labels are on the same device if using class-aware\n",
    "    if class_aware and labels is not None:\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        \n",
    "        for i in range(N):\n",
    "            top_k = top_k_indices[i, :k]\n",
    "            \n",
    "            if class_aware and labels is not None:\n",
    "                query_label = labels[i]\n",
    "                retrieved_labels = labels[top_k]\n",
    "                if (retrieved_labels == query_label).any():\n",
    "                    correct += 1\n",
    "            else:\n",
    "                if i in top_k:\n",
    "                    correct += 1\n",
    "        \n",
    "        results[f\"Recall@{k}\"] = 100.0 * correct / N\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_map(similarities, class_aware=False, labels=None):\n",
    "    \"\"\"Compute Mean Average Precision\"\"\"\n",
    "    N = similarities.shape[0]\n",
    "    device = similarities.device\n",
    "    \n",
    "    # Ensure everything is on CPU for numpy operations\n",
    "    similarities_cpu = similarities.cpu() if similarities.is_cuda else similarities\n",
    "    sorted_indices = torch.argsort(similarities_cpu, dim=1, descending=True)\n",
    "    \n",
    "    if labels is not None:\n",
    "        labels_cpu = labels.cpu() if labels.is_cuda else labels\n",
    "        labels_np = labels_cpu.numpy()\n",
    "    \n",
    "    average_precisions = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        sorted_idx = sorted_indices[i]\n",
    "        \n",
    "        if class_aware and labels is not None:\n",
    "            query_label = labels_np[i]\n",
    "            relevant_mask = (labels_np == query_label)\n",
    "        else:\n",
    "            relevant_mask = np.zeros(N, dtype=bool)\n",
    "            relevant_mask[i] = True\n",
    "        \n",
    "        precisions = []\n",
    "        num_relevant = 0\n",
    "        \n",
    "        for rank, idx in enumerate(sorted_idx, 1):\n",
    "            if relevant_mask[idx]:\n",
    "                num_relevant += 1\n",
    "                precisions.append(num_relevant / rank)\n",
    "        \n",
    "        if precisions:\n",
    "            average_precisions.append(np.mean(precisions))\n",
    "        else:\n",
    "            average_precisions.append(0.0)\n",
    "    \n",
    "    return np.mean(average_precisions)\n",
    "\n",
    "\n",
    "def evaluate_task2a(test_dataset, clip_model, clip_processor, clip_tokenizer, device):\n",
    "    \"\"\"Full evaluation for Task 2A\"\"\"\n",
    "    \n",
    "    # Extract embeddings\n",
    "    embeddings = extract_clip_embeddings(\n",
    "        test_dataset, clip_model, clip_processor, clip_tokenizer, device)\n",
    "    \n",
    "    image_emb = embeddings['image_embeddings'].to(device)\n",
    "    text_emb = embeddings['text_embeddings'].to(device)\n",
    "    labels = embeddings['labels']  # Keep on CPU initially\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = torch.mm(image_emb, text_emb.t())\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TASK 2A: IMAGE-CAPTION RETRIEVAL RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Instance-level Recall@K\n",
    "    print(\"\\n1. Instance-Level Recall@K:\")\n",
    "    instance_recall = compute_recall_at_k(similarities, k_values=[1, 3, 5])\n",
    "    for k, v in instance_recall.items():\n",
    "        print(f\"   {k}: {v:.2f}%\")\n",
    "    \n",
    "    # Class-aware Recall@K (labels will be moved to device inside function)\n",
    "    print(\"\\n2. Class-Aware Recall@K:\")\n",
    "    class_recall = compute_recall_at_k(similarities, k_values=[1, 3, 5], \n",
    "                                      class_aware=True, labels=labels)\n",
    "    for k, v in class_recall.items():\n",
    "        print(f\"   {k}: {v:.2f}%\")\n",
    "    \n",
    "    # MAP (will be computed on CPU inside function)\n",
    "    print(\"\\n3. Mean Average Precision:\")\n",
    "    instance_map = compute_map(similarities, labels=labels)\n",
    "    print(f\"   Instance-Level MAP: {instance_map:.4f}\")\n",
    "    \n",
    "    class_map = compute_map(similarities, class_aware=True, labels=labels)\n",
    "    print(f\"   Class-Aware MAP: {class_map:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'instance_recall': instance_recall,\n",
    "        'class_recall': class_recall,\n",
    "        'instance_map': instance_map,\n",
    "        'class_map': class_map,\n",
    "        'embeddings': embeddings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING TASK 2A: IMAGE-CAPTION RETRIEVAL\n",
      "============================================================\n",
      "Extracting embeddings for 4046 unique images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf04785a09534f54a6cfbbab1c5bf3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK 2A: IMAGE-CAPTION RETRIEVAL RESULTS\n",
      "============================================================\n",
      "\n",
      "1. Instance-Level Recall@K:\n",
      "   Recall@1: 27.63%\n",
      "   Recall@3: 44.86%\n",
      "   Recall@5: 53.51%\n",
      "\n",
      "2. Class-Aware Recall@K:\n",
      "   Recall@1: 96.69%\n",
      "   Recall@3: 98.10%\n",
      "   Recall@5: 98.64%\n",
      "\n",
      "3. Mean Average Precision:\n",
      "   Instance-Level MAP: 0.3994\n",
      "   Class-Aware MAP: 0.8308\n",
      "\n",
      "Task 2A (Image-Caption) Recall@5: 53.51%\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------\n",
    "# TASK 2A: IMAGE-CAPTION RETRIEVAL\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TASK 2A: IMAGE-CAPTION RETRIEVAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Task 2A: Evaluate CLIP on image-caption retrieval\n",
    "task2a_results = evaluate_task2a(test_ds, clip_model, clip_processor, \n",
    "                                  clip_tokenizer, DEVICE)\n",
    "\n",
    "print(f\"\\nTask 2A (Image-Caption) Recall@5: {task2a_results['instance_recall']['Recall@5']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2B: EEG-Caption Retrieval\n",
    "\n",
    "### EEG-to-CLIP Projection Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TASK 2B: EEG-CAPTION RETRIEVAL\n",
      "============================================================\n",
      "\n",
      "[1/5] Loading trained EEG encoder from Task 1...\n",
      "‚úì Loaded checkpoint from epoch 98\n",
      "‚úì Task 1 validation accuracy was: 9.50%\n",
      "‚úì EEG encoder loaded and ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TASK 2B: EEG-CAPTION RETRIEVAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the trained EEG encoder from Task 1\n",
    "print(\"\\n[1/5] Loading trained EEG encoder from Task 1...\")\n",
    "\n",
    "eeg_encoder = EEG_ViT_1D(num_subjects=13, num_classes=20).to(DEVICE)\n",
    "\n",
    "# Load your friend's checkpoint\n",
    "checkpoint = torch.load('best_model_vit_1d.pth', map_location=DEVICE)\n",
    "\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    eeg_encoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"‚úì Loaded checkpoint from epoch {checkpoint.get('epoch', '?')}\")\n",
    "    print(f\"‚úì Task 1 validation accuracy was: {checkpoint.get('val_acc', 0):.2f}%\")\n",
    "else:\n",
    "    eeg_encoder.load_state_dict(checkpoint)\n",
    "    print(\"‚úì Loaded model weights\")\n",
    "\n",
    "# Remove the classification heads - we only need the encoder part\n",
    "eeg_encoder.eval()\n",
    "\n",
    "print(\"‚úì EEG encoder loaded and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] Creating projection head for CLIP alignment...\n",
      "‚úì Projection head created\n",
      "  Trainable parameters: 164,608\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2/5] Creating projection head for CLIP alignment...\")\n",
    "\n",
    "class EEGToClipProjection(nn.Module):\n",
    "    \"\"\"Projects EEG embeddings to CLIP text embedding space\"\"\"\n",
    "    \n",
    "    def __init__(self, eeg_dim=128, clip_dim=512, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Small MLP projection head\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(eeg_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, clip_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, eeg_embedding):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eeg_embedding: (batch, 128) from EEG encoder's CLS token\n",
    "        Returns:\n",
    "            projected: (batch, 512) normalized CLIP-space embedding\n",
    "        \"\"\"\n",
    "        projected = self.projection(eeg_embedding)\n",
    "        # Normalize to unit length (CRITICAL for cosine similarity)\n",
    "        projected = F.normalize(projected, p=2, dim=-1)\n",
    "        return projected\n",
    "\n",
    "projection_head = EEGToClipProjection(eeg_dim=128, clip_dim=512).to(DEVICE)\n",
    "\n",
    "print(f\"‚úì Projection head created\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in projection_head.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] Implementing loss functions...\n",
      "‚úì Loss functions implemented:\n",
      "  - Cosine similarity (KD similarity-based)\n",
      "  - Debiased contrastive (InfoNCE with soft negatives)\n",
      "  - KL divergence (KD logit-based)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[3/5] Implementing loss functions...\")\n",
    "\n",
    "class Task2BLosses:\n",
    "    \"\"\"Loss functions for EEG-Caption alignment\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_similarity_loss(eeg_emb, text_emb):\n",
    "        \"\"\"\n",
    "        Knowledge Distillation: Similarity-based\n",
    "        Align EEG with ground-truth caption\n",
    "        \"\"\"\n",
    "        # Both should be normalized already\n",
    "        cosine_sim = torch.sum(eeg_emb * text_emb, dim=-1)  # (batch,)\n",
    "        loss = 1 - cosine_sim.mean()  # Want similarity = 1\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def contrastive_loss_debiased(eeg_emb, text_emb, labels, temperature=0.07):\n",
    "        \"\"\"\n",
    "        Debiased Contrastive Loss (InfoNCE with soft negatives)\n",
    "        Down-weights same-class captions in negative set\n",
    "        \n",
    "        Args:\n",
    "            eeg_emb: (batch, 512) normalized EEG embeddings\n",
    "            text_emb: (batch, 512) normalized text embeddings  \n",
    "            labels: (batch,) category labels\n",
    "            temperature: scaling factor\n",
    "        \"\"\"\n",
    "        batch_size = eeg_emb.shape[0]\n",
    "        \n",
    "        # Compute similarity matrix: (batch, batch)\n",
    "        logits = torch.mm(eeg_emb, text_emb.t()) / temperature\n",
    "        \n",
    "        # Create weight matrix for negatives\n",
    "        # Same class = lower weight, different class = full weight\n",
    "        labels_eq = labels.unsqueeze(0) == labels.unsqueeze(1)  # (batch, batch)\n",
    "        \n",
    "        # Diagonal = positives (weight doesn't matter, excluded from denominator)\n",
    "        # Same class = 0.3 weight, different class = 1.0 weight\n",
    "        weights = torch.where(labels_eq, \n",
    "                            torch.tensor(0.3, device=DEVICE),\n",
    "                            torch.tensor(1.0, device=DEVICE))\n",
    "        weights = weights.fill_diagonal_(0)  # Ignore diagonal in denominator\n",
    "        \n",
    "        # Compute loss\n",
    "        # Numerator: positive pairs (diagonal)\n",
    "        positive_logits = torch.diag(logits)  # (batch,)\n",
    "        \n",
    "        # Denominator: weighted sum of all pairs\n",
    "        exp_logits = torch.exp(logits)\n",
    "        weighted_exp = exp_logits * weights\n",
    "        \n",
    "        # Add back the positive (diagonal) \n",
    "        denominator = weighted_exp.sum(dim=1) + torch.exp(positive_logits)\n",
    "        \n",
    "        loss = -torch.log(torch.exp(positive_logits) / denominator).mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def kl_divergence_loss(eeg_emb, text_emb_all, image_emb, temperature_teacher=0.07, temperature_student=0.07):\n",
    "        \"\"\"\n",
    "        Knowledge Distillation: Logit-based\n",
    "        Student (EEG) mimics Teacher (CLIP image encoder) distribution\n",
    "        \n",
    "        Args:\n",
    "            eeg_emb: (batch, 512) student embeddings\n",
    "            text_emb_all: (N_captions, 512) all caption embeddings in dataset\n",
    "            image_emb: (batch, 512) teacher (CLIP image) embeddings\n",
    "            temperature_teacher/student: softmax temperatures\n",
    "        \"\"\"\n",
    "        # Teacher distribution: image -> all captions\n",
    "        teacher_logits = torch.mm(image_emb, text_emb_all.t()) / temperature_teacher\n",
    "        teacher_probs = F.softmax(teacher_logits, dim=-1)\n",
    "        \n",
    "        # Student distribution: EEG -> all captions  \n",
    "        student_logits = torch.mm(eeg_emb, text_emb_all.t()) / temperature_student\n",
    "        student_log_probs = F.log_softmax(student_logits, dim=-1)\n",
    "        \n",
    "        # KL divergence\n",
    "        kl_loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean')\n",
    "        \n",
    "        return kl_loss\n",
    "\n",
    "print(\"‚úì Loss functions implemented:\")\n",
    "print(\"  - Cosine similarity (KD similarity-based)\")\n",
    "print(\"  - Debiased contrastive (InfoNCE with soft negatives)\")\n",
    "print(\"  - KL divergence (KD logit-based)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] Setting up evaluation function...\n",
      "‚úì Evaluation function ready\n",
      "\n",
      "============================================================\n",
      "SETUP COMPLETE - Ready to train Task 2B!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[4/5] Setting up evaluation function...\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_eeg_caption_retrieval(eeg_encoder, projection_head, clip_model, \n",
    "                                   clip_tokenizer, dataloader, device, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate EEG-Caption retrieval\n",
    "    Returns Class-Aware Recall@K\n",
    "    \"\"\"\n",
    "    eeg_encoder.eval()\n",
    "    projection_head.eval()\n",
    "    clip_model.eval()\n",
    "    \n",
    "    all_eeg_emb = []\n",
    "    all_text_emb = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=f\"Evaluating Recall@{k}\", leave=False):\n",
    "        eeg_data = batch['eeg'].to(device)\n",
    "        captions = batch['caption']\n",
    "        labels = batch['label']\n",
    "        subject_ids = batch['subject_id'].to(device)\n",
    "        \n",
    "        # Get EEG embedding (same as training)\n",
    "        x = eeg_data\n",
    "        \n",
    "        # Dimension handling\n",
    "        if x.shape[1] == 500 and x.shape[2] == 122:\n",
    "            x = x.permute(0, 2, 1)\n",
    "        if x.shape[2] > 500:\n",
    "            x = x[:, :, :500]\n",
    "        \n",
    "        # Tokenize\n",
    "        x = eeg_encoder.tokenizer(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        b, seq_len, _ = x.shape\n",
    "        \n",
    "        # Add CLS token\n",
    "        cls_tokens = eeg_encoder.cls_token.expand(b, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        \n",
    "        # Add positional embedding\n",
    "        x = x + eeg_encoder.pos_embedding[:, :seq_len + 1, :]\n",
    "        \n",
    "        # Transformer\n",
    "        x = eeg_encoder.transformer(x)\n",
    "        \n",
    "        # Extract CLS token\n",
    "        eeg_cls = x[:, 0, :]\n",
    "        \n",
    "        # Project to CLIP space\n",
    "        eeg_projected = projection_head(eeg_cls)\n",
    "        \n",
    "        # Get text embedding\n",
    "        text_inputs = clip_tokenizer(captions, padding=True, truncation=True,\n",
    "                                     return_tensors=\"pt\", max_length=77)\n",
    "        text_inputs = {k: v.to(device) for k, v in text_inputs.items()}\n",
    "        text_emb = clip_model.get_text_features(**text_inputs)\n",
    "        text_emb = F.normalize(text_emb, p=2, dim=-1)\n",
    "        \n",
    "        all_eeg_emb.append(eeg_projected.cpu())\n",
    "        all_text_emb.append(text_emb.cpu())\n",
    "        all_labels.append(labels)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    eeg_emb = torch.cat(all_eeg_emb, dim=0).to(device)\n",
    "    text_emb = torch.cat(all_text_emb, dim=0).to(device)\n",
    "    labels = torch.cat(all_labels, dim=0).to(device)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarities = torch.mm(eeg_emb, text_emb.t())  # (N, N)\n",
    "    \n",
    "    # Get top-K indices for each query\n",
    "    top_k_indices = torch.argsort(similarities, dim=1, descending=True)[:, :k]\n",
    "    \n",
    "    # Compute class-aware Recall@K\n",
    "    correct = 0\n",
    "    for i in range(len(labels)):\n",
    "        query_label = labels[i]\n",
    "        retrieved_labels = labels[top_k_indices[i]]\n",
    "        if (retrieved_labels == query_label).any():\n",
    "            correct += 1\n",
    "    \n",
    "    recall = 100.0 * correct / len(labels)\n",
    "    return recall\n",
    "\n",
    "print(\"‚úì Evaluation function ready\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SETUP COMPLETE - Ready to train Task 2B!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/5] Setting up training function...\n",
      "‚úì Training function ready\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[5/5] Setting up training function...\")\n",
    "\n",
    "def train_task2b(eeg_encoder, projection_head, clip_model, clip_tokenizer, \n",
    "                 train_loader, val_loader,\n",
    "                 strategy='frozen', num_epochs=20, lr=1e-3, \n",
    "                 loss_weights={'cosine': 1.0, 'contrastive': 1.0}):\n",
    "    \"\"\"\n",
    "    Train EEG-Caption alignment with different CLIP fine-tuning strategies\n",
    "    \n",
    "    Args:\n",
    "        strategy: 'frozen', 'partial_unfreeze'\n",
    "        loss_weights: dict with keys 'cosine', 'contrastive'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with strategy: {strategy.upper()}\")\n",
    "    print(f\"Loss weights: {loss_weights}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Configure CLIP based on strategy\n",
    "    if strategy == 'frozen':\n",
    "        print(\"Strategy: CLIP fully frozen\")\n",
    "        for param in clip_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        trainable_params = list(projection_head.parameters())\n",
    "        \n",
    "    elif strategy == 'partial_unfreeze':\n",
    "        print(\"Strategy: Unfreezing last 2 CLIP layers + text projection\")\n",
    "        # Freeze all first\n",
    "        for param in clip_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze last 2 transformer layers\n",
    "        for layer in clip_model.text_model.encoder.layers[-2:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Unfreeze text projection\n",
    "        if hasattr(clip_model, 'text_projection'):\n",
    "            for param in clip_model.text_projection.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        trainable_params = list(projection_head.parameters())\n",
    "        for layer in clip_model.text_model.encoder.layers[-2:]:\n",
    "            trainable_params.extend(list(layer.parameters()))\n",
    "        if hasattr(clip_model, 'text_projection'):\n",
    "            trainable_params.extend(list(clip_model.text_projection.parameters()))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    total_trainable = sum(p.numel() for p in trainable_params if p.requires_grad)\n",
    "    print(f\"\\nTrainable parameters: {total_trainable:,}\")\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(trainable_params, lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "    # Loss computer\n",
    "    loss_computer = Task2BLosses()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_recall = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # ===== TRAINING =====\n",
    "        eeg_encoder.eval()  # Keep EEG encoder frozen\n",
    "        projection_head.train()\n",
    "        if strategy != 'frozen':\n",
    "            clip_model.train()\n",
    "        else:\n",
    "            clip_model.eval()\n",
    "        \n",
    "        epoch_losses = {'total': 0, 'cosine': 0, 'contrastive': 0}\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "            eeg_data = batch['eeg'].to(DEVICE)\n",
    "            captions = batch['caption']\n",
    "            labels = batch['label'].to(DEVICE)\n",
    "            subject_ids = batch['subject_id'].to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get EEG embedding using model's forward pass\n",
    "            # We need to extract intermediate representation before classification heads\n",
    "            with torch.no_grad():\n",
    "                # Forward through tokenizer and transformer\n",
    "                x = eeg_data\n",
    "                \n",
    "                # Dimension handling (from model's forward)\n",
    "                if x.shape[1] == 500 and x.shape[2] == 122:\n",
    "                    x = x.permute(0, 2, 1)\n",
    "                if x.shape[2] > 500:\n",
    "                    x = x[:, :, :500]\n",
    "                \n",
    "                # Tokenize\n",
    "                x = eeg_encoder.tokenizer(x)\n",
    "                x = x.permute(0, 2, 1)\n",
    "                \n",
    "                b, seq_len, _ = x.shape\n",
    "                \n",
    "                # Add CLS token\n",
    "                cls_tokens = eeg_encoder.cls_token.expand(b, -1, -1)\n",
    "                x = torch.cat((cls_tokens, x), dim=1)\n",
    "                \n",
    "                # Add positional embedding\n",
    "                x = x + eeg_encoder.pos_embedding[:, :seq_len + 1, :]\n",
    "                \n",
    "                # Transformer\n",
    "                x = eeg_encoder.transformer(x)\n",
    "                \n",
    "                # Extract CLS token\n",
    "                eeg_cls = x[:, 0, :]  # (batch, 128)\n",
    "            \n",
    "            # Project to CLIP space\n",
    "            eeg_projected = projection_head(eeg_cls)  # (batch, 512), normalized\n",
    "            \n",
    "            # Get text embeddings from CLIP\n",
    "            text_inputs = clip_tokenizer(captions, padding=True, truncation=True,\n",
    "                                        return_tensors=\"pt\", max_length=77)\n",
    "            text_inputs = {k: v.to(DEVICE) for k, v in text_inputs.items()}\n",
    "            \n",
    "            text_emb = clip_model.get_text_features(**text_inputs)\n",
    "            text_emb = F.normalize(text_emb, p=2, dim=-1)\n",
    "            \n",
    "            # Compute losses\n",
    "            total_loss = 0\n",
    "            \n",
    "            if loss_weights.get('cosine', 0) > 0:\n",
    "                loss_cos = loss_computer.cosine_similarity_loss(eeg_projected, text_emb)\n",
    "                total_loss += loss_weights['cosine'] * loss_cos\n",
    "                epoch_losses['cosine'] += loss_cos.item()\n",
    "            \n",
    "            if loss_weights.get('contrastive', 0) > 0:\n",
    "                loss_contrast = loss_computer.contrastive_loss_debiased(\n",
    "                    eeg_projected, text_emb, labels)\n",
    "                total_loss += loss_weights['contrastive'] * loss_contrast\n",
    "                epoch_losses['contrastive'] += loss_contrast.item()\n",
    "            \n",
    "            epoch_losses['total'] += total_loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print epoch stats\n",
    "        avg_total = epoch_losses['total'] / num_batches\n",
    "        avg_cos = epoch_losses['cosine'] / num_batches\n",
    "        avg_contrast = epoch_losses['contrastive'] / num_batches\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Total Loss: {avg_total:.4f} \" +\n",
    "              f\"(Cosine: {avg_cos:.4f}, Contrastive: {avg_contrast:.4f})\")\n",
    "        \n",
    "        # ===== VALIDATION =====\n",
    "        if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:  # Validate every 5 epochs and last epoch\n",
    "            val_recall = evaluate_eeg_caption_retrieval(\n",
    "                eeg_encoder, projection_head, clip_model, clip_tokenizer, \n",
    "                val_loader, DEVICE, k=5)\n",
    "            \n",
    "            print(f\"  ‚Üí Val Recall@5: {val_recall:.2f}%\")\n",
    "            \n",
    "            if val_recall > best_val_recall:\n",
    "                best_val_recall = val_recall\n",
    "                save_path = f'task2b_best_{strategy}.pth'\n",
    "                torch.save({\n",
    "                    'projection_head': projection_head.state_dict(),\n",
    "                    'epoch': epoch + 1,\n",
    "                    'strategy': strategy,\n",
    "                    'val_recall': val_recall,\n",
    "                    'loss_weights': loss_weights\n",
    "                }, save_path)\n",
    "                print(f\"  ‚úì Best model saved to {save_path}!\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training complete!\")\n",
    "    print(f\"Best Val Recall@5: {best_val_recall:.2f}%\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return projection_head, best_val_recall\n",
    "\n",
    "print(\"‚úì Training function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING TASK 2B - STRATEGY: FROZEN CLIP\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Training with strategy: FROZEN\n",
      "Loss weights: {'cosine': 0.5, 'contrastive': 0.5}\n",
      "============================================================\n",
      "\n",
      "Strategy: CLIP fully frozen\n",
      "\n",
      "Trainable parameters: 164,608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78920cd628454037a35e95598c90cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Total Loss: 1.9141 (Cosine: 0.4146, Contrastive: 3.4136)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208e72bb676c489fad0a2a4b1d2a0088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Total Loss: 1.8699 (Cosine: 0.3669, Contrastive: 3.3729)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc58829518a4fe8828db8dcbd9f936b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Total Loss: 1.8612 (Cosine: 0.3663, Contrastive: 3.3560)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7c9a94e3b842c68543b06956c1bf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Total Loss: 1.8544 (Cosine: 0.3674, Contrastive: 3.3414)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01f720d321a4490a5dc1823c5639573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Total Loss: 1.8480 (Cosine: 0.3682, Contrastive: 3.3279)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9cfacc37e24514871ed038ee0c2606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating Recall@5:   0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚Üí Val Recall@5: 14.12%\n",
      "  ‚úì Best model saved to task2b_best_frozen.pth!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911eb85730ae459a998405487d2c3822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Total Loss: 1.8432 (Cosine: 0.3707, Contrastive: 3.3156)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071ab29b9f1e47d1882a67a4841ea030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Total Loss: 1.8370 (Cosine: 0.3734, Contrastive: 3.3005)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee69e92fc357431cbc639f08493c2ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING TASK 2B - STRATEGY: FROZEN CLIP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create fresh projection head\n",
    "projection_head_frozen = EEGToClipProjection(eeg_dim=128, clip_dim=512).to(DEVICE)\n",
    "\n",
    "# Train with frozen CLIP (baseline)\n",
    "trained_projection, best_recall = train_task2b(\n",
    "    eeg_encoder=eeg_encoder,\n",
    "    projection_head=projection_head_frozen,\n",
    "    clip_model=clip_model,\n",
    "    clip_tokenizer=clip_tokenizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    strategy='frozen',\n",
    "    num_epochs=20,\n",
    "    lr=1e-3,\n",
    "    loss_weights={'cosine': 0.5, 'contrastive': 0.5}\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Training completed with best validation Recall@5: {best_recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (eegenv)",
   "language": "python",
   "name": "eegenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
